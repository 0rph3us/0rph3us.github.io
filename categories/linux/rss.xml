<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Linux on Michael im Netz</title>
    <link>http://localhost:1313/categories/linux/</link>
    <description>Recent content in Linux on Michael im Netz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>de-DE</language>
    <copyright>Diese Seite ist unter der &lt;a href=&#34;http://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt; lizenziert.</copyright>
    <lastBuildDate>Mon, 20 Apr 2015 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/linux/rss/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>kaputtes System nach Restore mit Obnam</title>
      <link>http://localhost:1313/post/2015/04/kaputtes-system-nach-restore-mit-obnam/</link>
      <pubDate>Mon, 20 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2015/04/kaputtes-system-nach-restore-mit-obnam/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://obnam.org/&#34;&gt;Obnam&lt;/a&gt; ist ein nettes Backup-Tool, welches ich auf meinen Laptop unter Ubuntu 14.04 verwende.
Ich wollte die Tage einen Restore von einer Datei machen und habe sie inplace wieder herstellen wollen.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo obnam --generation=243130 restore --to=/  /etc/apt/sources.list.d/adiscon-v8-stable-trusty.list
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Danach war meine aktuelle Session im Eimer und ich habe meinen Rechner neu gestartet. Danach gab es eine
große Überraschung: Ich konnte mich nicht mehr einloggen. Nach dem ersten Schreck, dass obnam vielleicht
die Platte geschrottet hat, habe ich mit &lt;a href=&#34;https://grml.org/&#34;&gt;grml&lt;/a&gt; auf die Platte geschaut. Alles war da. Nach einiger Zeit
habe ich festgestellt, dass obnam die Rechte von / auf 700 geändert hat. Nachdem ich / wieder auf 755 geändert
habe ging alles.&lt;/p&gt;

&lt;p&gt;Es ist leider reproduzierbar, dass obnam die Rechte alle Verzechnisse beim Restore kaputt macht, welche
es nicht unter Kontrolle hat. Aus diesem Grund mache ich einen Restore jetzt wie folgt:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo obnam --generation=243130 restore --to=/home/rennecke/restore  /etc/apt/sources.list.d/adiscon-v8-stable-trusty.list
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Das aktuelle Verhalten ist ein absolutes No-Go! Ich verwende die Version 1.9 aus &lt;a href=&#34;https://launchpad.net/~chris-bigballofwax/+archive/ubuntu/obnam-ppa&#34;&gt;dieser PPA&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Einen DNS Server selbst betreiben</title>
      <link>http://localhost:1313/post/2015/03/einen-dns-server-selbst-betreiben/</link>
      <pubDate>Wed, 18 Mar 2015 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2015/03/einen-dns-server-selbst-betreiben/</guid>
      <description>

&lt;p&gt;Ich habe mir die Tage einen eigenen &lt;a href=&#34;http://de.wikipedia.org/wiki/Domain_Name_System&#34;&gt;DNS&lt;/a&gt;-Server aufgesetzt. Er macht das Leben einfacher, wenn
man mehrere Dienste im eigenen Netzwerk betreibt. Dazu habe ich &lt;a href=&#34;https://www.powerdns.com/&#34;&gt;PowerDNS&lt;/a&gt; mit einem &lt;a href=&#34;http://de.wikipedia.org/wiki/MySQL&#34;&gt;MySQL&lt;/a&gt;-Backend.
Das ganze lässt sich mit der Weboberfläche &lt;a href=&#34;http://www.poweradmin.org/&#34;&gt;poweradmin&lt;/a&gt; sehr einfach bedienen. Man sollte aber bedenken,
dass jeder Fehler ein komisches Verhalten zur Folge haben kann, wenn man z.B. &lt;a href=&#34;http://de.wikipedia.org/wiki/Zone_%28DNS%29&#34;&gt;Zone&lt;/a&gt; im DNS überschreibt.&lt;/p&gt;

&lt;p&gt;Die Installation auf dem &lt;a href=&#34;http://www.raspberrypi.org/help/what-is-a-raspberry-pi/&#34;&gt;Raspberry Pi&lt;/a&gt; mit &lt;a href=&#34;http://www.raspbian.org/&#34;&gt;Raspbian&lt;/a&gt; gestaltet sich realtiv einfach. Am besten macht macht
das ganze als &lt;code&gt;root&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;installation-von-mysql:816d60a4fac4f6ba0b121cbbf32c84d1&#34;&gt;Installation von MySQL&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt-get install mysql-server mysql-client php5-mysql
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Danach habt Ihr MySQL installiert und auch den php Client, welchen wir später noch brauchen. Während
der Installation werdet ihr nach dem &lt;code&gt;root&lt;/code&gt;-Passwort für den MySQL Server gefragt.&lt;/p&gt;

&lt;h3 id=&#34;installation-von-powerdns:816d60a4fac4f6ba0b121cbbf32c84d1&#34;&gt;Installation von PowerDNS&lt;/h3&gt;

&lt;p&gt;Die Installation möchte Euch bei der Einrichtung der Datenbank behilflich sein. Aber wir konfigurieren
alles per Hand. Bei mir die automatische Konfiguration nicht so gut funktioniert.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo su
apt-get install pdns-server pdns-backend-mysql dnsutils
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;einrichten-der-datenbank:816d60a4fac4f6ba0b121cbbf32c84d1&#34;&gt;Einrichten der Datenbank&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE DATABASE powerdns;
GRANT ALL ON powerdns.* TO powerdns@127.0.0.1 IDENTIFIED BY &#39;GeheimesPasswort&#39;;
FLUSH PRIVILEGES;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Das muss man in die &lt;code&gt;mysql&lt;/code&gt; Konsole eintragen. Zu dieser gelangt man so:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mysql -uroot -p
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nun importieren wir das Datenbank-Schema für PowerDNS&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mysql -uroot -p powerdns &amp;lt; /usr/share/doc/pdns-backend-mysql/nodnssec-3.x_to_3.4.0_schema.mysql.sql
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;powerdns-konfigurieren:816d60a4fac4f6ba0b121cbbf32c84d1&#34;&gt;PowerDNS konfigurieren&lt;/h3&gt;

&lt;p&gt;Die Datei &lt;code&gt;/etc/powerdns/pdns.d/pdns.local.gmysql.conf&lt;/code&gt; muss wie folgt verändert werden:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# MySQL Configuration
#
# Launch gmysql backend
launch+=gmysql

# gmysql parameters
gmysql-host=127.0.0.1
gmysql-port=3306
gmysql-dbname=powerdns
gmysql-user=powerdns
gmysql-password=GeheimesPasswort
gmysql-dnssec=yes
# gmysql-socket=
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nun muss  man sie noch schützen &lt;code&gt;sudo chmod 660 /etc/powerdns/pdns.d/pdns.local.gmysql.conf&lt;/code&gt;. Nun
wurder Der Server nur lokal funktionieren und nur seine eigenen Zonen auflösen können. Damit man
er auch noch über alle anderen Zonen Auskunft geben kann und jedes Gerät im LAN ihn nutzen kann
muss man ein paar Zeilen in der &lt;code&gt;/etc/powerdns/pdns.conf&lt;/code&gt; ändern
(sie sind schön auskommentiert enthälten, ohne Parameter).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;recursor=8.8.8.8

allow-recursion=127.0.0.1,192.168.0.0/24
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ich gehe davon aus, dass Euer LAN ein 192.168.0.0/24 Netz ist, sonst anpassen ;-).&lt;/p&gt;

&lt;h3 id=&#34;test:816d60a4fac4f6ba0b121cbbf32c84d1&#34;&gt;Test&lt;/h3&gt;

&lt;p&gt;Wenn alles funktioniert, dann kann man den DNS Server wie folgt testen:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dig google.de @8.8.8.8  

; &amp;lt;&amp;lt;&amp;gt;&amp;gt; DiG 9.9.5-3ubuntu0.2-Ubuntu &amp;lt;&amp;lt;&amp;gt;&amp;gt; google.de @127.0.0.1
;; global options: +cmd
;; Got answer:
;; -&amp;gt;&amp;gt;HEADER&amp;lt;&amp;lt;- opcode: QUERY, status: NOERROR, id: 49993
;; flags: qr rd ra; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 512
;; QUESTION SECTION:
;google.de.                     IN      A

;; ANSWER SECTION:
google.de.              299     IN      A       173.194.32.255
google.de.              299     IN      A       173.194.32.248
google.de.              299     IN      A       173.194.32.239
google.de.              299     IN      A       173.194.32.247

;; Query time: 87 msec
;; SERVER: 8.8.8.8#53(8.8.8.8)
;; WHEN: Wed Mar 18 07:12:42 CET 2015
;; MSG SIZE  rcvd: 102
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;poweradmin-installieren:816d60a4fac4f6ba0b121cbbf32c84d1&#34;&gt;Poweradmin installieren&lt;/h3&gt;

&lt;p&gt;Damit man den DNS Server einfach/schnell bedienen kann, installiert man &lt;a href=&#34;http://www.poweradmin.org/&#34;&gt;poweradmin&lt;/a&gt;. Das ist
eine php-Anwendung mit der man seinen PowerDNS Server einfach konfigurieren kann.&lt;/p&gt;

&lt;p&gt;Als erstes installiert man einen Webserver und php. Auf dem Raspberry Pi macht sich in meinen
Augen &lt;a href=&#34;http://nginx.org/&#34;&gt;Nginx&lt;/a&gt; ganz gut. Wie man diesen installiert kann man in &lt;a href=&#34;http://localhost:1313/post/2014/07/webserver-auf-dem-raspberry-pi-installieren/&#34;&gt;diesem Artikel&lt;/a&gt; nachlesen.&lt;/p&gt;

&lt;p&gt;Um mit der eigenlichen Installation zu beginnen muss man nich php-mcrypt installieren.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install php5-mcrypt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nun beginnt die Installtion&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo su
cd /var/www
wget https://github.com/poweradmin/poweradmin/archive/v2.1.7.zip
unzip v2.1.7.zip
rm v2.1.7.zip
mv poweradmin-2.1.7 poweradmin
cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/nginx/sites-available/powerdns
server {
    listen 80;
    server_name &amp;lt;IP des Raspberry Pi&amp;gt;;
    
    root /var/www/poweradmin;
    index index.html index.php;
    
    location / {
        try_files $uri $uri/ /index.php?$args;
    }

    location ~ ^(.+\.php)(.*)$ {
        try_files $fastcgi_script_name =404;
        fastcgi_split_path_info  ^(.+\.php)(.*)$;
        fastcgi_pass   unix:/var/run/php5-fpm.sock;
        fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;
        fastcgi_param  PATH_INFO        $fastcgi_path_info;
        include        /etc/nginx/fastcgi_params;
    }

    access_log      /var/log/nginx/poweradmin.access.log;
    error_log       /var/log/nginx/poweradmin.error.log;
}
EOF
ln -s /etc/nginx/sites-available/powerdns /etc/nginx/sites-enabled/powerdns
service nginx reload
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nun kann man seinen Server einfach konfigurieren. Dazu öffnet man http://&lt;IP Raspberry Pi&gt; im Browser
und konfiguriert erst einmal Poweradmin und dann kann man gleich loslegen mit dem anlegfen von neuen
Zonen. Das ganze ist recht selbsterklärend.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Modernes Logging Teil 2</title>
      <link>http://localhost:1313/post/2015/02/modernes-logging-teil-2/</link>
      <pubDate>Tue, 24 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2015/02/modernes-logging-teil-2/</guid>
      <description>

&lt;p&gt;Ich habe in meinen &lt;a href=&#34;http://localhost:1313/post/2015/02/modernes-logging/&#34;&gt;letzten Beitrag über Logging&lt;/a&gt; schon geschrieben, wie man eine moderne Logging-Infrastruktur aufsetzten kann.
Inzwischen wurde &lt;a href=&#34;http://www.elasticsearch.org/overview/kibana/&#34;&gt;Kibana&lt;/a&gt; in der Version 4 finale freigegeben. In diesem Artikel möchte ich das Upgrade auf die
finale Version zeigen und auf das &lt;a href=&#34;http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/setup-repositories.html&#34;&gt;Repository von Elasticsearch&lt;/a&gt; hinweisen.&lt;/p&gt;

&lt;p&gt;Kibana in der finalen Version 4 lässt sich genauso installieren, wie der Release Candidate. Man muss nur die Konfiguration
im Elasticsearch anpassen.&lt;/p&gt;

&lt;h3 id=&#34;vorarbeiten:568e9c6fc3669f1cee0d24068e094cd2&#34;&gt;Vorarbeiten&lt;/h3&gt;

&lt;p&gt;Als erstes fährt man Kibana herunter und updatet Elasricsearch auf die Version 1.4.4. Das geht sehr einfach, wenn man das
entsprechende &lt;a href=&#34;http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/setup-repositories.html&#34;&gt;Repository&lt;/a&gt; benutzt. Dann ist es nur noch ein &lt;code&gt;apt-get install elasticsearch&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;update-auf-kibana-4:568e9c6fc3669f1cee0d24068e094cd2&#34;&gt;Update auf Kibana 4&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;wget https://download.elasticsearch.org/kibana/kibana/kibana-4.0.0-linux-x64.tar.gz
tar xfvz kibana-4.0.0-linux-x64.tar.gz

# Index updaten
BODY=`curl -XGET &#39;localhost:9200/.kibana/config/4.0.0-rc1/_source&#39;`; curl -XPUT &amp;quot;localhost:9200/.kibana/config/4.0.0&amp;quot; -d &amp;quot;$BODY&amp;quot; &amp;amp;&amp;amp; curl -XDELETE &amp;quot;localhost:9200/.kibana/config/4.0.0-rc1&amp;quot;

# kibana starten
kibana-4.0.0-linux-x64/bin/kibana
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;nachtrag-06-03-2015:568e9c6fc3669f1cee0d24068e094cd2&#34;&gt;Nachtrag 06.03.2015&lt;/h3&gt;

&lt;p&gt;Es wurde &lt;a href=&#34;https://www.elasticsearch.org/blog/kibana-4-0-1-released/&#34;&gt;Kibana 4.0.1&lt;/a&gt; released. Diese Version hat ein paar Bugfixes und man auch den Index nicht updaten, wenn man den Release Candidate noch installiert hat.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pakete selbst bauen</title>
      <link>http://localhost:1313/post/2015/02/pakete-selbst-bauen/</link>
      <pubDate>Thu, 19 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2015/02/pakete-selbst-bauen/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://binfalse.de/&#34;&gt;binfalse&lt;/a&gt; hat mich dazu gebracht diesen Artiel zu schreiben. Die verschiedenen Paketformate der Linux-Distrubutionen können Softwareentwickler vor Probleme stellen, die ihre Software leicht installierbar gestalten möchten. Debian und Ubuntu setzen auf &lt;a href=&#34;http://de.wikipedia.org/wiki/Debian-Paket&#34;&gt;deb&lt;/a&gt;-Pakete während RedHat und Fedora auf &lt;a href=&#34;http://de.wikipedia.org/wiki/RPM_Package_Manager&#34;&gt;rpm&lt;/a&gt;-Pakete setzen. Diese beiden Fromate nicht nicht kompartibel zueinander. Die Werkzeuge, um die Pakte zu erstellen können viele als unnötig kompliziert befinden. Das schreckt ab, wenn man das Paket nur für sich oder für eine kleine Gruppe von Nutzern baut. Es ist auch durchaus sinnvoll &lt;strong&gt;Sktripte&lt;/strong&gt; zu paketetieren, da sich die Paketverwaltung um die Anhänigkeiten kümmern kann.&lt;/p&gt;

&lt;p&gt;Um unnötige Komplikationen zu vermeiden, gibt es Tool &lt;a href=&#34;https://github.com/jordansissel/fpm/wiki&#34;&gt;fpm&lt;/a&gt;. Es kann unter anderm deb- und rpm-Pakete erstellen. fpm ist in &lt;a href=&#34;https://www.ruby-lang.org/de/&#34;&gt;ruby&lt;/a&gt; geschrieben. Aus diesem Grund muss man etwas Vorarbeit leisten.&lt;/p&gt;

&lt;h3 id=&#34;installation-von-fpm-unter-ubuntu-debian:697271e97aa2539a916944cbda9fcb5e&#34;&gt;Installation von fpm unter Ubuntu/Debian&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo apt-get update
sudo apt-get install ruby-dev build-essential
sudo gem install fpm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Wenn das &lt;a href=&#34;http://guides.rubygems.org/what-is-a-gem/&#34;&gt;gem&lt;/a&gt; &lt;code&gt;fpm&lt;/code&gt; installiert ist, dann gibt es den Befehl &lt;code&gt;fpm&lt;/code&gt; im &lt;code&gt;PATH&lt;/code&gt;. Man kann das ganze wie folgt testen:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;fpm -h
Intro:

  This is fpm version 1.3.3

  If you think something is wrong, it&#39;s probably a bug! :)
  Please file these here: https://github.com/jordansissel/fpm/issues

  You can find support on irc (#fpm on freenode irc) or via email with
  fpm-users@googlegroups.com

Usage:
    fpm [OPTIONS] [ARGS] ...

...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nun kann man anfangen Pakte zu bauen. Ein Aufruf sieht im einfachsten Fall so aus: &lt;code&gt;fpm -s source_type -t target_type  source_name_or_location&lt;/code&gt; Der &lt;strong&gt;source_type&lt;/strong&gt; bzw. &lt;strong&gt;target_type&lt;/strong&gt; können die verschiedensten Paketformate sein. Einige Pakettype benötigen Hilfsprogramme, damit &lt;code&gt;fpm&lt;/code&gt; sie erstellen kann. Da ich annehme, dass &lt;code&gt;fpm&lt;/code&gt; auf einen Debian bzw. Ubuntu benutzt wird, zeige ich im folgenden Beispiel wie man aus einen &lt;a href=&#34;http://guides.rubygems.org/what-is-a-gem/&#34;&gt;ruby&lt;/a&gt; ein deb-Paket baut.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;fpm -s gem -t deb bundler
Erstellt package {: path =&amp;gt; &amp;quot;rubygem-bundler_1.6.5_all.deb&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Es wird die Datei &lt;code&gt;rubygem-bundler_1.6.5_all.deb&lt;/code&gt; im aktuellen Verzeichnis erstellt. (Ihre Versionsnummer kann abweichen). Diese kann man dann ganz einfach installieren (oder zu einen Repository hinzufügen).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo dpkg -i rubygem-bundler_1.6.5_all.de
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Wenn die Quelle ein &lt;strong&gt;Standart Reporitory&lt;/strong&gt; wie &lt;a href=&#34;https://rubygems.org/&#34;&gt;rubygems.org&lt;/a&gt; für ruby gems  oder  &lt;a href=&#34;https://www.npmjs.com/&#34;&gt;npm&lt;/a&gt; für &lt;a href=&#34;http://nodejs.org/&#34;&gt;nodejs&lt;/a&gt; Pakete, dann ist fpm in der Lage automatisch alle benötigten Dateien herunterzuladen.&lt;/p&gt;

&lt;p&gt;Es ist auch sehr einfach möglich fremde Software zu packen, welche man compilieren muss. Im Allgemeinen sieht das wie folgt aus:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# Vorbereitung
mkdir ~/build
cd ~/build
git clone https://github.com/cool/cool-app
cd cool-app

# bauen
make
mkdir -p /tmp/cool-app 
make install DESTDIR=/tmp/cool-app
fpm -s -t dir deb -C /tmp/cool-app \
  --name cool-app-name \
  --version 1.0.0 \
  --iteration 1 \
  --depends &amp;quot;Abhänigkeit 1 (&amp;gt;= 2.0.0)&amp;quot; \
  --depends &amp;quot;Abhänigkeit 2&amp;quot; \
  --description &amp;quot;Ein Beispielpaket&amp;quot; \
 .

fpm -s -t dir rpm -C /tmp/cool-app \
  --name cool-app-name \
  --version 1.0.0 \
  --iteration 1 \
  --depends &amp;quot;Abhänigkeit 1 (&amp;gt;= 2.0.0)&amp;quot; \
  --depends &amp;quot;Abhänigkeit 2&amp;quot; \
  --description &amp;quot;Ein Beispielpaket&amp;quot; \
  .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Man erhält dann im aktuellen Verzeichnis ein &lt;code&gt;rpm&lt;/code&gt;- und ein &lt;code&gt;deb&lt;/code&gt;-Paket. So kann man einfach und schnell Pakete für das eigene System bauen oder für andere, wenn man z.B. selbst Software bereit stellt. Man kann auch statt des &lt;code&gt;.&lt;/code&gt; am Ende des &lt;code&gt;fpm&lt;/code&gt;-Komandos sagt, dass der gesamte Inhalt von unter &lt;code&gt;/tmp/cool-app&lt;/code&gt; in das Paket soll. Man kann/sollte auch die Vezeichnisse einzeln angeben z.B. &lt;code&gt;etc/cool-app usr/bin usr/share/man&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&#34;sources:697271e97aa2539a916944cbda9fcb5e&#34;&gt;Sources&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;gem&lt;/strong&gt; ruby-gem (automatischer Download)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;python&lt;/strong&gt; &lt;a href=&#34;https://www.python.org/&#34;&gt;python&lt;/a&gt;-Module, welche &lt;code&gt;easy_install&lt;/code&gt; unterstützen (automatischer Download)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pear&lt;/strong&gt; &lt;a href=&#34;http://php.net/&#34;&gt;php&lt;/a&gt;-Module (automatischer Download von &lt;a href=&#34;http://pear.php.net/&#34;&gt;pear.php.net&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;dir&lt;/strong&gt; Verzeichnis&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;tar&lt;/strong&gt; &lt;a href=&#34;http://de.wikipedia.org/wiki/Tar&#34;&gt;tar&lt;/a&gt;-Archiv&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pear&lt;/strong&gt; php-Module (automatischer Download)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;rpm&lt;/strong&gt; &lt;a href=&#34;http://de.wikipedia.org/wiki/RPM_Package_Manager&#34;&gt;rpm&lt;/a&gt;-Paket&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;deb&lt;/strong&gt; deb-Paket&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;zip&lt;/strong&gt; &lt;a href=&#34;http://de.wikipedia.org/wiki/ZIP-Dateiformat&#34;&gt;zip&lt;/a&gt;-Archiv&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;empty&lt;/strong&gt; erzeugt ein leeres Paket, welches man oft für Metapakte benutzt&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;npm&lt;/strong&gt; nodejs Module (automaticher Download)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cpan&lt;/strong&gt; peal-Module (automatischer Download)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;osxpkg&lt;/strong&gt; Mac OS X Pakete (nur auf Mac verfügbar)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;targets:697271e97aa2539a916944cbda9fcb5e&#34;&gt;Targets&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;deb&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;rpm&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;zip&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;tar&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;dir&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;sh&lt;/strong&gt; (selbst entpackendes Shell skript, welches ein &lt;a href=&#34;http://www.bzip.org/&#34;&gt;bzip2&lt;/a&gt; gepacktes tar enthält)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;osxpkg&lt;/strong&gt; (nur auf Mac verfügbar)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;solaris&lt;/strong&gt; Solaris Pakete (nur auf Solaris möglich)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pkgin&lt;/strong&gt; BSD pakete (nur auf BSD möglich)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;puppet&lt;/strong&gt; (&lt;a href=&#34;http://puppetlabs.com/puppet/what-is-puppet&#34;&gt;puppet&lt;/a&gt;-Modul, aktuell noch nicht implementiert)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Modernes Logging</title>
      <link>http://localhost:1313/post/2015/02/modernes-logging/</link>
      <pubDate>Sun, 15 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2015/02/modernes-logging/</guid>
      <description>

&lt;p&gt;Achtung: Es gibt einen &lt;a href=&#34;http://localhost:1313/post/2015/02/modernes-logging-teil-2/&#34;&gt;2. Teil des Artikels&lt;/a&gt;, welchen sich vorher ansehen solle, bevor man hier alles copy&amp;amp;pastet&lt;/p&gt;

&lt;p&gt;In &lt;a href=&#34;http://de.wikipedia.org/wiki/Java_%28Programmiersprache%29&#34;&gt;Java&lt;/a&gt;-Welt ist folgende Stack für Logging recht verbreitet, weil man mit ihm ein leistungsstarkes modernes und zentrales Logging umsetzten kann. Dieser Stack besteht aus &lt;a href=&#34;http://www.elasticsearch.org/&#34;&gt;Elasticsearch&lt;/a&gt;, einen Volltextindex zum speichern der Nahrichten. Diese werden von &lt;a href=&#34;http://logstash.net/&#34;&gt;Logstash&lt;/a&gt; verarbeitet und zum Index geschickt. &lt;a href=&#34;http://www.elasticsearch.org/overview/kibana/&#34;&gt;Kibana&lt;/a&gt; wird zum
visualisieren der Volltextinhalte genommen. Ich finde Logstash zum reinen verschicken von Lognahrichten zu schwergewichtig und es bötigt zu viel Ressourcen. Linux verwendet &lt;a href=&#34;http://de.wikipedia.org/wiki/Syslog&#34;&gt;syslog&lt;/a&gt; zum versenden von Lognachrichten. In vieles Distributionen wird &lt;a href=&#34;http://www.rsyslog.com/&#34;&gt;rsyslog&lt;/a&gt; zum verarbeiten der Nahrichten verwendet. Das gute ist, dass man mit rsyslog auch direkt in Elasticsearch loggen kann. So kann man mit rsyslog, Elasticsearch und Kibana ein leichtgewichtigeres und modernes Logsystem bauen.&lt;/p&gt;

&lt;p&gt;Die folgende Anleitung beschreibt, wie man das ganze unter Ubuntu 14.04 einrichtet. Ich beschreibe kein komplettes Setup, es ist als Einstieg in die Thematik gedacht.&lt;/p&gt;

&lt;h3 id=&#34;rsyslog-unter-ubuntu-14-04-installieren:0f1926dffb36411c33c28d4643e7a8d5&#34;&gt;rsyslog unter Ubuntu 14.04 installieren&lt;/h3&gt;

&lt;p&gt;Eine Konsole öffnen und das Repository hinzufügen. Es handelt sich hierbei um das &lt;a href=&#34;http://www.rsyslog.com/ubuntu-repository/&#34;&gt;offizelle Repository&lt;/a&gt; von rsyslog. Rsyslog ist in den offizellen Repositories von Ubuntu nicht auf dem neusten Stand, außerdem gibt kein Paket mit dem Elasticsearchsupport.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo add-apt-repository ppa:adiscon/v8-stable
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Den Cache von &lt;code&gt;apt&lt;/code&gt; aktualisieren und &lt;code&gt;rsyslog&lt;/code&gt; mit der Elasticsearch Unterstützung installieren&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo apt-get update
sudo apt-get install rsyslog rsyslog-elasticsearch
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;elasticsearch-installieren:0f1926dffb36411c33c28d4643e7a8d5&#34;&gt;Elasticsearch installieren&lt;/h3&gt;

&lt;p&gt;deb-Paket herunterladen und installieren. Die Installation über das deb-Paket hat den Vorteil, dass man Elasticsearch einfach updaten kann und es gibt auch schon init-Skripte.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;wget https://download.elasticsearch.org/elasticsearch/elasticsearch/elasticsearch-1.4.3.deb
sudo dpkg -i elasticsearch-1.4.3.deb
sudo update-rc.d elasticsearch defaults
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Elasticsearch konfigurieren. Dazu muss man die Datei &lt;code&gt;/etc/elasticsearch/elasticsearch.yml&lt;/code&gt; im Editor seine Wahl öffnen und die folgenden Zeilen einkommentieren und ändern&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# Set the number of shards (splits) of an index (5 by default):
#
index.number_of_shards: 1

# Set the number of replicas (additional copies) of an index (1 by default):
#
index.number_of_replicas: 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Elasticsearch starten:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo service elasticsearch start
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;rsyslog-konfigurieren:0f1926dffb36411c33c28d4643e7a8d5&#34;&gt;rsyslog konfigurieren&lt;/h3&gt;

&lt;p&gt;Man muss nun dafür sorgen, dass die Lognahrichten von rsyslog nach Elasticsearch geschrieben werden. Als erstes legt man ein &lt;a href=&#34;http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping.html&#34;&gt;Mapping&lt;/a&gt; in Elasticsearch an. Damit sagt man Elasticsearch, dass es das Feld &lt;code&gt;program&lt;/code&gt; &lt;a href=&#34;http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-core-types.html&#34;&gt;nicht analysieren&lt;/a&gt; soll. Außerdem sollen die Dokumente nach &lt;a href=&#34;http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-ttl-field.html&#34;&gt;90 Tagen gelöscht&lt;/a&gt; werden.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -XPUT &#39;http://localhost:9200/logstash&#39; -d &#39;{
  &amp;quot;mappings&amp;quot;: {
    &amp;quot;events&amp;quot; : {
      &amp;quot;_ttl&amp;quot; : {
        &amp;quot;enabled&amp;quot; : true,
        &amp;quot;default&amp;quot; : &amp;quot;90d&amp;quot;
        },
      &amp;quot;properties&amp;quot; : {
        &amp;quot;program&amp;quot; : {
          &amp;quot;type&amp;quot; : &amp;quot;string&amp;quot;,
          &amp;quot;index&amp;quot; : &amp;quot;not_analyzed&amp;quot;,
          &amp;quot;norms&amp;quot; : {
            &amp;quot;enabled&amp;quot; : false
          }
        }
      }
    }
  }
}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nach man die Datei  &lt;code&gt;/etc/rsyslog.d/30-elasticsearch.conf&lt;/code&gt; erstellt hat, muss
man nur noch &lt;code&gt;rsyslog&lt;/code&gt; neu starten. Wenn es Probleme gibt kann man mit &lt;code&gt;rsyslogd -N1&lt;/code&gt; die Konfiguraion überprüfen.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo su -
cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/rsyslog.d/30-elasticsearch.conf
#module(load=&amp;quot;imuxsock&amp;quot;)       # for listening to /dev/log, normal not needed
module(load=&amp;quot;omelasticsearch&amp;quot;) # for outputting to Elasticsearch

# this is for index names to be like: logstash-YYYY.MM.DD
template(name=&amp;quot;logstash-index&amp;quot;
  type=&amp;quot;list&amp;quot;) {
    constant(value=&amp;quot;logstash-&amp;quot;)
    property(name=&amp;quot;timereported&amp;quot; dateFormat=&amp;quot;rfc3339&amp;quot; position.from=&amp;quot;1&amp;quot; position.to=&amp;quot;4&amp;quot;)
    constant(value=&amp;quot;.&amp;quot;)
    property(name=&amp;quot;timereported&amp;quot; dateFormat=&amp;quot;rfc3339&amp;quot; position.from=&amp;quot;6&amp;quot; position.to=&amp;quot;7&amp;quot;)
    constant(value=&amp;quot;.&amp;quot;)
    property(name=&amp;quot;timereported&amp;quot; dateFormat=&amp;quot;rfc3339&amp;quot; position.from=&amp;quot;9&amp;quot; position.to=&amp;quot;10&amp;quot;)
}

# use only one index, useful only for local usage
template(name=&amp;quot;logstash&amp;quot; type=&amp;quot;string&amp;quot; string=&amp;quot;logstash&amp;quot;)

# this is for formatting our syslog in JSON with @timestamp
template(name=&amp;quot;plain-syslog&amp;quot;
  type=&amp;quot;list&amp;quot;) {
    constant(value=&amp;quot;{&amp;quot;)
      constant(value=&amp;quot;\&amp;quot;@timestamp\&amp;quot;:\&amp;quot;&amp;quot;)     property(name=&amp;quot;timereported&amp;quot; dateFormat=&amp;quot;rfc3339&amp;quot;)
      constant(value=&amp;quot;\&amp;quot;,\&amp;quot;host\&amp;quot;:\&amp;quot;&amp;quot;)        property(name=&amp;quot;hostname&amp;quot;)
      constant(value=&amp;quot;\&amp;quot;,\&amp;quot;severity\&amp;quot;:\&amp;quot;&amp;quot;)    property(name=&amp;quot;syslogseverity-text&amp;quot;)
      constant(value=&amp;quot;\&amp;quot;,\&amp;quot;facility\&amp;quot;:\&amp;quot;&amp;quot;)    property(name=&amp;quot;syslogfacility-text&amp;quot;)
      constant(value=&amp;quot;\&amp;quot;,\&amp;quot;tag\&amp;quot;:\&amp;quot;&amp;quot;)         property(name=&amp;quot;syslogtag&amp;quot; format=&amp;quot;json&amp;quot;)
      constant(value=&amp;quot;\&amp;quot;,\&amp;quot;program\&amp;quot;:\&amp;quot;&amp;quot;)     property(name=&amp;quot;programname&amp;quot;)
      constant(value=&amp;quot;\&amp;quot;,\&amp;quot;message\&amp;quot;:\&amp;quot;&amp;quot;)     property(name=&amp;quot;msg&amp;quot; format=&amp;quot;json&amp;quot;)
    constant(value=&amp;quot;\&amp;quot;}&amp;quot;)
}

# this is where we actually send the logs to Elasticsearch (localhost:9200 by default)
action(type=&amp;quot;omelasticsearch&amp;quot;
    template=&amp;quot;plain-syslog&amp;quot;
    searchIndex=&amp;quot;logstash&amp;quot;
    dynSearchIndex=&amp;quot;on&amp;quot;)

EOF
/etc/init.d/rsyslog restart
exit
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;kibana-installieren:0f1926dffb36411c33c28d4643e7a8d5&#34;&gt;Kibana installieren&lt;/h3&gt;

&lt;p&gt;Für Kibana gibt es leider keinen bequemen Installationsweg. Deswegen beschreibe ich den Weg, der schnell und einfach zum Ziel führt, aber auf keinen Fall sinnvoll für den produktiven Betrieb ist. Man läd Kibana herunter und startet es.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;wget https://download.elasticsearch.org/kibana/kibana/kibana-4.0.0-rc1-linux-x64.tar.gz
tar xfvz kibana-4.0.0-rc1-linux-x64.tar.gz
kibana-4.0.0-rc1-linux-x64/bin/kibana
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nun kann man auf Kibana über &lt;code&gt;http://127.0.0.1:5601/&lt;/code&gt; im Browser zugreifen. Man muss nur noch Kibana sagen, welchen Index es benutzen soll. Das geht realtiv intuitiv.&lt;/p&gt;

&lt;h3 id=&#34;anmerkung:0f1926dffb36411c33c28d4643e7a8d5&#34;&gt;Anmerkung&lt;/h3&gt;

&lt;p&gt;Das es rsyslog auch für Windows gibt, kann man diesen Stack auch für Windows nutzen. Ich habe hier alle Technologien nur angeschitten, für ein richtiges Setup muss man noch viel mehr beachten und konfigurieren.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Skripte parallelisieren</title>
      <link>http://localhost:1313/post/2015/02/skripte-parallelisieren/</link>
      <pubDate>Thu, 12 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2015/02/skripte-parallelisieren/</guid>
      <description>

&lt;p&gt;Für viele Aufgaben bei meiner täglichen Arbeit mit Linux nutze ich &lt;a href=&#34;http://tiswww.case.edu/php/chet/bash/bashtop.html&#34;&gt;bash&lt;/a&gt;-Skripte bzw. tippe sie gleich auf der Komandozeile ein. Es gibt viele Aufgaben welche &lt;em&gt;langwierig&lt;/em&gt; sind und leicht parallelisierbar sind. Hier kann das Programm &lt;a href=&#34;http://www.gnu.org/software/parallel/&#34;&gt;parallel&lt;/a&gt; helfen. Im einfachsten Fall stellt man es sich wie eine Art Queueing-System vor. Die Aufgabenpakete werden in eine Warteschlange gesteckt und &lt;code&gt;n&lt;/code&gt; Prozesse arbeiten die Warteschlange ab. Wenn man nichts konfiguriert, dann ist &lt;code&gt;n&lt;/code&gt; die Anzahl der Prozessorkerne.&lt;/p&gt;

&lt;p&gt;Man kann &lt;code&gt;parallel&lt;/code&gt; als Ersatz für &lt;code&gt;xargs&lt;/code&gt; nehmen oder um Schleifen zu parallelisieren. Auf der Seite von &lt;code&gt;parallel&lt;/code&gt; gibt es viele &lt;a href=&#34;http://www.gnu.org/software/parallel/man.html&#34;&gt;Beispiele&lt;/a&gt;, welche über das parallelisieren von Schleifen hinaus gehen.&lt;/p&gt;

&lt;h3 id=&#34;aktueller-anwendungsfall:cb1bfcf9cf27c64f5ffffa51a1dd92e0&#34;&gt;Aktueller Anwendungsfall&lt;/h3&gt;

&lt;p&gt;Ich nutze &lt;code&gt;parallel&lt;/code&gt; zum erstellen von Backups. Dazu kopiere ich sehr viele kleine Dateien auf eine &lt;a href=&#34;http://de.wikipedia.org/wiki/Network_File_System&#34;&gt;NFS&lt;/a&gt;-Freigabe. Ich habe &lt;a href=&#34;http://rsync.samba.org/&#34;&gt;rsync&lt;/a&gt; und &lt;code&gt;cp&lt;/code&gt; probiert. &lt;code&gt;rsync&lt;/code&gt; ist in meinen Fall langsamer als &lt;code&gt;cp&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Aus diesem Grund habe ich &lt;code&gt;cp&lt;/code&gt;, wie folgt parallelisiert:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;find . -type f -mtime -2 | parallel --jobs 16 /usr/sbin/backup_helper.sh {}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Es werden alle Dateien gesucht, welche jünger als 2 Tage sind. Diese werden mit 16 parallelen &lt;code&gt;cp&lt;/code&gt; auf das NFS-Share kopiert. So bekomme meine 1GBit Netzwerkanbindung während des Backups ausgelastet. Beim sequenziellen kopieren bzw. mit &lt;code&gt;rsync&lt;/code&gt; bin ich nicht über 100MBit/s gekommen.&lt;/p&gt;

&lt;p&gt;Das script &lt;code&gt;backup_helper.sh&lt;/code&gt; sieht wie folgt aus:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cat /usr/sbin/backup_helper.sh
#!/bin/bash

base=&amp;quot;$(dirname ${1})&amp;quot;
mkdir -p &amp;quot;/backup/${base}&amp;quot;
cp &amp;quot;${1}&amp;quot; &amp;quot;/backup/${1}&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>RSS Reader selbst betreiben</title>
      <link>http://localhost:1313/post/2014/09/rss-reader-selbst-betreiben/</link>
      <pubDate>Wed, 17 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2014/09/rss-reader-selbst-betreiben/</guid>
      <description>

&lt;p&gt;Nach meinen Wissen gab es eine Zeit, in der RSS-Feeds als Old-School und damit
als nicht mehr zeitgemäß galten. Ich finde, dass sie zur Zeit immer beliebter
werden. Ich möchte meine Feeds immer dabei und nicht viele Apps auf dem Smartphone
installieren, nur um meinen 20 News-Seiten zu folgen. Das ganze im Browser zu
lesen kann auf mobilen Devices nervig werden, entweder ist die mobile Seite nicht
wirklich brauchbar oder man hat zu viele Seite, welche man lesen möchte.&lt;/p&gt;

&lt;p&gt;Da viele Seiten einen &lt;a href=&#34;http://de.wikipedia.org/wiki/Web-Feed&#34;&gt;Feed&lt;/a&gt; anbieten, kann man diese abonnieren und in einen
Feed-Reader zusammen führen. Es gibt Menschen, wie mich, die keinen Reader wie
&lt;a href=&#34;http://feedly.com/&#34;&gt;Feedly&lt;/a&gt; nutzen möchten.&lt;/p&gt;

&lt;p&gt;Mit einem &lt;a href=&#34;http://www.raspberrypi.org/&#34;&gt;Raspberry Pi&lt;/a&gt; kann man einfach selbst einen RSS-Reader an der heimischen
DSL-Leitung betreiben. Dazu benutze ich &lt;a href=&#34;http://nginx.org/&#34;&gt;Nginx&lt;/a&gt; als Webserver, &lt;a href=&#34;http://www.mysql.de/&#34;&gt;MySQL&lt;/a&gt; als Datenbank
sowie &lt;a href=&#34;http://tt-rss.org/&#34;&gt;Tiny Tiny RSS&lt;/a&gt; als Reader. Als Betriebssystem nutze ich Raspbian.&lt;/p&gt;

&lt;h2 id=&#34;nginx-installieren:589edeb4b03d933707b2122f6cfd44ac&#34;&gt;Nginx installieren&lt;/h2&gt;

&lt;p&gt;Wie man &lt;a href=&#34;http://nginx.org/&#34;&gt;Nginx&lt;/a&gt; installiert, habe ich in &lt;a href=&#34;http://localhost:1313/post/2014/07/webserver-auf-dem-raspberry-pi-installieren/&#34;&gt;diesem Artikel&lt;/a&gt; schon erklärt.
Je nach dem wie paranoid bzw. nerdig man ist, sollte man die Verbindung noch
mit SSL/TLS absichern.&lt;/p&gt;

&lt;h2 id=&#34;mysql-installieren:589edeb4b03d933707b2122f6cfd44ac&#34;&gt;MySQL installieren&lt;/h2&gt;

&lt;p&gt;Die grundlegende Installation von MySQL geht leicht von der Hand. Da man nur einige
Pakte installieren muss. Die nötige Datenbank ist auch schnell eingerichtet.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# zu root werden
sudo su -

apt-get update
apt-get install mysql-server mysql-client php5-mysql php5-curl

# Datenbanken einrichten
mysql -p
Enter password:
Welcome to the MySQL monitor.  Commands end with ; or \g.
[...]
mysql&amp;gt; CREATE DATABASE ttrss;
Query OK, 1 row affected (0.01 sec)
 
mysql&amp;gt; GRANT ALL ON ttrss.* TO ttrss@localhost IDENTIFIED BY &#39;GeheimesPasswort&#39;;
Query OK, 0 rows affected (0.02 sec)
 
mysql&amp;gt; exit
Bye
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;mysql-härten:589edeb4b03d933707b2122f6cfd44ac&#34;&gt;MySQL härten&lt;/h3&gt;

&lt;p&gt;Mit dem folgenden Tool kann man seine MySQL noch härten. Dazu löscht
es die Test-Datenbanken und anonyme Benutzer. Weiterhin ist ein
Remote Login für den Benutzer &lt;code&gt;root&lt;/code&gt; nicht mehr möglich.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# zu root werden
sudo su -
mysql_secure_installation
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;tiny-tiny-rss-installieren:589edeb4b03d933707b2122f6cfd44ac&#34;&gt;Tiny Tiny RSS installieren&lt;/h2&gt;

&lt;p&gt;Man lädt sich die &lt;a href=&#34;https://github.com/gothfox/Tiny-Tiny-RSS/releases&#34;&gt;aktuellste Version&lt;/a&gt; von &lt;a href=&#34;http://tt-rss.org/&#34;&gt;Tiny Tiny RSS&lt;/a&gt; in das Document Root-Verzeichnis
von Nginx und entpackt es&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# zu root werden
sudo su -
cd /usr/share/nginx/www
wget https://github.com/gothfox/Tiny-Tiny-RSS/archive/1.13.tar.gz
tar xfvz 1.13.tar.gz
mv Tiny-Tiny-RSS-1.13/ tt-rss/
chown -R www-data:www-data tt-rss/
rm 1.13.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nachdem man das alles gemacht hat, führt man die Installation von Tiny Tiny RSS im Browser fort. Dazu
&lt;code&gt;http(s)://IP/tt-rss/install/&lt;/code&gt;
Dort wählen wir MySQL in dem Feld &lt;em&gt;Database type&lt;/em&gt;, geben als &lt;em&gt;Username&lt;/em&gt; und &lt;em&gt;Database name&lt;/em&gt;
&lt;em&gt;ttrss&lt;/em&gt; an und geben das Passwort, welches für den MySQL Benutzer &lt;em&gt;ttrss&lt;/em&gt; angelegt hat,
in das Feld &lt;em&gt;Password&lt;/em&gt; ein. Der Port ist 3306. In das Feld &lt;em&gt;Host name&lt;/em&gt; schreiben wir 127.0.0.1
Anschließend klicken wir auf &lt;em&gt;Test configuration&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Wenn alles richtig war, dann erscheint &lt;em&gt;Database test succeeded&lt;/em&gt;. Nach einem Klick auf
&lt;em&gt;Initialize database&lt;/em&gt; können wir aus der Textbox die Konfiguration kopieren.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo su -
cat &amp;lt;&amp;lt; EOF &amp;gt; /usr/share/nginx/www/tt-rss/config.php
kopierten Text hier einfügen
EOF  
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;feeds-aktualisieren:589edeb4b03d933707b2122f6cfd44ac&#34;&gt;Feeds aktualisieren&lt;/h3&gt;

&lt;p&gt;Dazu muss man die folgende Zeile in die &lt;code&gt;crontab&lt;/code&gt; von &lt;code&gt;root&lt;/code&gt; eintragen:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;*/30 * * * * su www-data -s /bin/bash -c &#39;/usr/bin/php /var/www/tt-rss/update.php --feeds --quiet&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;tiny-tiny-rss-für-das-smartphone:589edeb4b03d933707b2122f6cfd44ac&#34;&gt;Tiny Tiny RSS für das Smartphone&lt;/h2&gt;

&lt;p&gt;Es gibt zwei Android Clients für Tiny Tiny RSS. Diese haben beide den Nachteil, dass sie unter Umständen
Probleme mit den Ciphers der SSL Verschlüsselung haben. Da das bei mir der Fall war bin ich auf eine HTML
App umgestiegen, welche auch noch auf meinen Raspberry Pi läuft. Dazu muss man nur &lt;a href=&#34;https://github.com/mboinet/ttrss-mobile/archive/1.0-1.tar.gz&#34;&gt;dieses Archiv&lt;/a&gt; herunter
laden und entpacken, alternativ kann man auch das &lt;a href=&#34;https://github.com/mboinet/ttrss-mobile&#34;&gt;dazugehörige git-Repository&lt;/a&gt; klonen.&lt;/p&gt;

&lt;p&gt;Man muss vorher sicherstellen, dass der API-Zugriff zu Tiny Tiny RSS erlaubt ist. Man loggt sich als ersten
in TT-RSS ein und klickt dann auf &lt;em&gt;Aktionen&lt;/em&gt; -&amp;gt; &lt;em&gt;Einstellungen&lt;/em&gt; und &lt;em&gt;Aktiviere API-Zugang&lt;/em&gt; muss ein grünes
Häkchen haben (wenn nicht anklicken).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo su -
cd /usr/share/nginx/www
wget https://github.com/mboinet/ttrss-mobile/archive/1.0-1.tar.gz
tar xfvz 1.0-1.tar.gz
mv ttrss-mobile-1.0-1 mobile
cp mobile/scripts/conf.js{-dist,}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nun kann man unter &lt;code&gt;http(s)://IP/mobile/&lt;/code&gt; die HTML5 Anwendung für das Smartphone erreichen.&lt;/p&gt;

&lt;h2 id=&#34;schlussbemerkung:589edeb4b03d933707b2122f6cfd44ac&#34;&gt;Schlussbemerkung&lt;/h2&gt;

&lt;p&gt;Soll der soeben installierte Dienst auch außerhalb des eigenen Netzwerkes verfügbar sein, so müssen
folgende Ports (80 und 443) im Router freigegeben werden.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Webserver auf dem Raspberry Pi installieren</title>
      <link>http://localhost:1313/post/2014/07/webserver-auf-dem-raspberry-pi-installieren/</link>
      <pubDate>Thu, 31 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2014/07/webserver-auf-dem-raspberry-pi-installieren/</guid>
      <description>

&lt;p&gt;Da man auf dem &lt;a href=&#34;http://www.raspberrypi.org/&#34;&gt;Raspberry Pi&lt;/a&gt; nicht sehr viele Ressourcen zur Verfügung hat, scheidet &lt;a href=&#34;http://httpd.apache.org/&#34;&gt;Apache&lt;/a&gt; als
Webserver für mich aus. Ich habe &lt;a href=&#34;http://www.lighttpd.net/&#34;&gt;lighttpd&lt;/a&gt; und &lt;a href=&#34;http://nginx.org&#34;&gt;Nginx&lt;/a&gt; ausprobiert. Von &lt;a href=&#34;http://www.lighttpd.net/&#34;&gt;lighttpd&lt;/a&gt; war ich am
Anfang sehr überzeugt. Er kann alles was man benötigt. Als mein Setup komplizierter wurde, war
ich nicht mehr in Lage in die Ideen mit &lt;a href=&#34;http://www.lighttpd.net/&#34;&gt;lighttpd&lt;/a&gt; umzusetzen. Die Ursache liegt weniger im
Funktionsumfang, sondern an den zur Verfügung stehenden Tutorials, Beispielkonfigurationen sowie der
Default-Konfiguration wenn man &lt;a href=&#34;http://www.lighttpd.net/&#34;&gt;lighttpd&lt;/a&gt; bei Raspbian installiert. Den endgültigen &lt;em&gt;Todesstoß&lt;/em&gt; hat
&lt;a href=&#34;http://www.lighttpd.net/&#34;&gt;lighttpd&lt;/a&gt; bekommen, als ich &lt;a href=&#34;https://www.phusionpassenger.com/&#34;&gt;Passanger&lt;/a&gt; ausprobieren wollte. Für &lt;a href=&#34;http://httpd.apache.org/&#34;&gt;Apache&lt;/a&gt; und &lt;a href=&#34;http://nginx.org&#34;&gt;Nginx&lt;/a&gt; gibt es fertige
&lt;a href=&#34;https://www.phusionpassenger.com/&#34;&gt;Passanger&lt;/a&gt;-Module bzw. funktionierenden Install-Skripte. Ich möchte nicht sagen, dass &lt;a href=&#34;http://www.lighttpd.net/&#34;&gt;lighttpd&lt;/a&gt; schlechter
als &lt;a href=&#34;http://nginx.org&#34;&gt;Nginx&lt;/a&gt; ist, aber ich bin bei &amp;ldquo;komplexen&amp;rdquo; Setups mit mehreren virtuellen Hosts und rewrite-Magie
besser mit &lt;a href=&#34;http://nginx.org&#34;&gt;Nginx&lt;/a&gt; zurecht gekommen.&lt;/p&gt;

&lt;p&gt;Im folgenden werde ich mich auf &lt;a href=&#34;http://nginx.org&#34;&gt;Nginx&lt;/a&gt; &lt;em&gt;Engine-X&lt;/em&gt; konzentrieren. da es für ihn sehr viele Tutorials
gibt und er sehr ressourcenschonend ist, ist er meiner Meinung nach die erste Wahl für den &lt;a href=&#34;http://www.raspberrypi.org/&#34;&gt;Raspberry Pi&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Viele werden mit nur einen Webserver nicht glücklich, weil ein Webserver nur statische Inhalte ausliefert.
Damit Nginx php ausliefern kann benötigt man php auf seinen Rechner sowie den
PHP Fast CGI Process Manager. Dieser verwaltet php-Prozesse, welche wiederum statisches HTML generieren
und an den Nginx weiter geben.&lt;/p&gt;

&lt;h2 id=&#34;nginx-mit-php-installieren-und-einrichten:db017475119777d596b8e698842c0f61&#34;&gt;Nginx mit php installieren und einrichten&lt;/h2&gt;

&lt;p&gt;Vor der Installation von neuen Pakten sollte man nachsehen, ob es Updates gibt. Ein
sicherheitsbewusster Admin aktualisiert jeden Tag seine Systeme,
gerade wenn sie öffentlich erreichbar sind.&lt;/p&gt;

&lt;p&gt;{% highlight bash %}&lt;/p&gt;

&lt;h1 id=&#34;zu-root-werden:db017475119777d596b8e698842c0f61&#34;&gt;zu root werden&lt;/h1&gt;

&lt;p&gt;sudo su -&lt;/p&gt;

&lt;p&gt;apt-get update
apt-get upgrade&lt;/p&gt;

&lt;p&gt;apt-get install nginx php5-fpm php5-cgi php5-cli php5-common
{% endhighlight %}&lt;/p&gt;

&lt;h3 id=&#34;nginx-konfigurieren:db017475119777d596b8e698842c0f61&#34;&gt;Nginx konfigurieren&lt;/h3&gt;

&lt;p&gt;Wenn man nur einen virtuellen Host einrichten möchte, kann man die gesamte Konfiguration in der
&lt;code&gt;/etc/nginx/ningx.conf&lt;/code&gt; erledigen. Das Aufteilen der Konfiguration in mehrere Dateien macht diese
übersichtlicher. Somit ist es auch möglich virtuelle Host zu aktivieren und zu deaktivieren.&lt;/p&gt;

&lt;p&gt;Meine Empfehlung ist, dass jede Applikation/Seite ein eigener Host ist. So hat jede Applikation
ihr eigenes Log-File und eine übersichtliche Konfiguration.
Der Nachteil ist, dass man mehrere (Sub) Domains benötigt. Das ist nicht
mit allen Dyndns Anbietern möglich.&lt;/p&gt;

&lt;p&gt;Konfigurationen, welche global gültig sind, schreibe ich auch
in die &lt;code&gt;/etc/nginx/ningx.conf&lt;/code&gt;. Das sind z.B. ssl-Offloading, Redirekt zu https und die
ssl-Konfiguration.&lt;/p&gt;

&lt;p&gt;Das ist eine exemplarische Konfiguration eines Host, welcher php ausführt und auf Port 80 lauscht.
Der Host lauscht auf die Namen &lt;em&gt;localhost&lt;/em&gt; und &lt;em&gt;awesomephp.example.com&lt;/em&gt;. Port 80 ist der
Standardport für http. Wenn ihr nur einen Host konfiguriert habt (nur ein server-Abschnitt), dann
wird dieser immer genommen, unabhängig davon was im host-Header der Anfrage steht.&lt;/p&gt;

&lt;p&gt;{% highlight nginx %}
server {
    listen 80;
    server_name localhost awesomephp.example.com;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root /var/www/awesomephp;
index index.html index.php;

location / {
    try_files $uri $uri/ /index.php?$args;
}

location ~ ^(.+\.php)(.*)$ {
    try_files $fastcgi_script_name =404;
    fastcgi_split_path_info  ^(.+\.php)(.*)$;
    fastcgi_pass   unix:/var/run/php5-fpm.sock;
    fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;
    fastcgi_param  PATH_INFO        $fastcgi_path_info;
    include        /etc/nginx/fastcgi_params;
}

access_log      /var/log/nginx/awesome.access.log;
error_log       /var/log/nginx/awesome.error.log;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;Nachdem der Nginx konfiguriert ist muss man die Konfiguration nur noch neu laden.&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
service nginx reload
{% endhighlight %}&lt;/p&gt;

&lt;h3 id=&#34;test-der-konfiguration:db017475119777d596b8e698842c0f61&#34;&gt;Test der Konfiguration&lt;/h3&gt;

&lt;p&gt;Nachdem der Nginx fehlerfrei seine Konfiguration neu geladen hat bzw. neu gestartet wurde kann man sie mit dem
folgenden Minimalbeispiel testen:&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
mkdir -p /var/www/awesomephp
echo &amp;ldquo;&amp;lt;? phpinfo(); /&amp;gt;&amp;rdquo; &amp;gt; /var/www/awesomephp/info.php
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;Wenn nur ein Host konfiguriert ist, dann kann man jetzt Browser &lt;code&gt;http://192.168.1.100/info.php&lt;/code&gt; aufrufen
und es erscheint eine Übersicht der php-Einstellungen. Ich gehe davon aus, dass der Raspberry Pi die IP
192.168.1.100 hat.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Raspberry Pi auf Jessie updaten</title>
      <link>http://localhost:1313/post/2014/07/raspberry-pi-auf-jessie-updaten/</link>
      <pubDate>Mon, 21 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2014/07/raspberry-pi-auf-jessie-updaten/</guid>
      <description>

&lt;p&gt;Das aktuell Raspbian basiert auf Debian 7 &amp;ldquo;Wheezy&amp;rdquo;. Seit einiger Zeit gibt
es auch Raspbian Pakete für Debian 8 &amp;ldquo;Jessie&amp;rdquo;. Jessie ist der Nachfolger von &amp;ldquo;Wheezy&amp;rdquo;.
Die Pakete von &amp;ldquo;Jessie&amp;rdquo; sind um einiges aktueller, als die von &amp;ldquo;Wheezy&amp;rdquo;. Das bedeutet
aber, dass sie nicht unbedingt so stabil sein können. Ich habe bis jetzt noch keine
negativen Erfahrungen gemacht.&lt;/p&gt;

&lt;h3 id=&#34;aktualisierung-ausführen:91ca631d89320c543d2d97dabdf66c3d&#34;&gt;Aktualisierung ausführen&lt;/h3&gt;

&lt;p&gt;Die folgenden Schritte müssen alle als Benutzer &lt;strong&gt;root&lt;/strong&gt; ausgeführt werden. Entweder man
loggt sie als &lt;strong&gt;root&lt;/strong&gt; ein,  man schreibt &lt;code&gt;sudo&lt;/code&gt; vor jedes Komando oder man öffnet eine
root-Shell mit &lt;code&gt;sudo -i&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Man muss die &lt;code&gt;/etc/apt/sources.list&lt;/code&gt; editieren. Dazu öffnet man sie mit einem Editor
der Wahl (ich bevorzuge vi ;-)) und man ändert alle vorkommen von &lt;strong&gt;wheezy&lt;/strong&gt; in &lt;strong&gt;jessie&lt;/strong&gt;.
Das ganze lässt sich auch automatisch mit &lt;code&gt;sed&lt;/code&gt; machen.&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
cp /etc/apt/sources.list{,.$(date +%F)} &amp;amp;&amp;amp; sed -e &amp;rsquo;s/wheezy/jessie/g&amp;rsquo; -i /etc/apt/sources.list
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;Wenn man nicht weiß was man macht, dann sollte man die Datei lieber per Hand editieren. Bei mir gibt es nur
eine Zeile und diese sollte dann wie folgt aussehen:&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
deb &lt;a href=&#34;http://mirrordirector.raspbian.org/raspbian/&#34;&gt;http://mirrordirector.raspbian.org/raspbian/&lt;/a&gt; jessie main contrib non-free rpi
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;Und nun muss man nur noch den Raspberry Pi updaten:&lt;/p&gt;

&lt;p&gt;{% highlight bash %}
apt-get update &amp;amp;&amp;amp; apt-get dist-upgrade
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;Das Update kann sehr lange dauern. Anschließend muss man den Raspberry Pi neu starten und das Update ist beendet!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Neuer Blog</title>
      <link>http://localhost:1313/post/2014/07/neuer-blog/</link>
      <pubDate>Thu, 17 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2014/07/neuer-blog/</guid>
      <description>

&lt;p&gt;Ich habe mich entschlossen, meinen alten &lt;a href=&#34;http://wpde.org/&#34;&gt;Wordpress&lt;/a&gt;-Blog einzudampfen. Ich
fand Wordpress schon immer recht schwergewichtig, aber ich kannte bis jetzt keine Alternative um einen
&amp;ldquo;gut&amp;rdquo; aussehenden Blog mit &amp;ldquo;wenig&amp;rdquo; Arbeit zu pflegen.&lt;/p&gt;

&lt;p&gt;Nun bin ich auf &lt;a href=&#34;http://jekyllbootstrap.com&#34;&gt;JekyllBootstrap&lt;/a&gt; und &lt;a href=&#34;https://github.com/dhulihan/hooligan&#34;&gt;Hooligan&lt;/a&gt; gestoßen.
Am Theme habe ich etwas etwas Hand angelegt. Als
Versionsverwaltung nutze ich &lt;a href=&#34;http://git-scm.com/&#34;&gt;git&lt;/a&gt;. Der gesamte Blog ist als
Code auf &lt;a href=&#34;https://github.com/0rph3us/jekyll-bootstrap&#34;&gt;github&lt;/a&gt; zu finden.&lt;/p&gt;

&lt;p&gt;Da ich nun offline am Blog arbeiten kann, möchte ich wieder aktiver sein.&lt;/p&gt;

&lt;h2 id=&#34;der-alte:35e6c4eaf33501dfb90b608aab77ae63&#34;&gt;Der Alte&lt;/h2&gt;

&lt;p&gt;Ich habe bzw. bin noch dabei die gesamten Inhalte des alten Wordpress zu portieren. Das meiste habe
ich automatisch migriert. Dadurch kann es noch Leichen im Layout geben. Ich werde nach und nach
die alten Posts überarbeiten.&lt;/p&gt;

&lt;h2 id=&#34;technik:35e6c4eaf33501dfb90b608aab77ae63&#34;&gt;Technik&lt;/h2&gt;

&lt;p&gt;Die erste Version des Blogs wird auf meinen Raspberry Pi laufen. Als Webserver verwende ich Nginx, außerdem
verwende ich Varnish zum cachen. Ich hoffe, dass mit diesem Setup die Geschwindigkeit des Blog
erträglich bleibt.&lt;/p&gt;

&lt;p&gt;In weiteren Beiträgen werde ich schreiben wie das Setup genau aussieht. Ich auch noch etwas
am ausprobieren.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Gnome-Keyring und Xfce</title>
      <link>http://localhost:1313/post/2013/12/gnome-keyring-und-xfce/</link>
      <pubDate>Tue, 31 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2013/12/gnome-keyring-und-xfce/</guid>
      <description>&lt;p&gt;Ich bin seit kurzen von &lt;a href=&#34;http://www.gnome.org/&#34;&gt;Gnome&lt;/a&gt; auf &lt;a href=&#34;http://www.xfce.org/&#34;&gt;Xfce&lt;/a&gt; umgestiegen.
Dabei ist mir die folgende Fehlermeldung öfter einmal durch die Konsole gelaufen:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;WARNING: gnome-keyring:: couldn&#39;t connect to: /home/rennecke/.cache/keyring-4OkyiQ/pkcs11: No such file or directory
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Das ganze lässt sich beheben, wenn man in der &lt;code&gt;/etc/xdg/autostart/gnome-keyring-pkcs11.desktop&lt;/code&gt; die folgende Zeile von:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;OnlyShowIn=GNOME;Unity;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;in&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;OnlyShowIn=GNOME;Unity;XFCE
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ändert. Nach dem neu anmelden bzw. Neustarten ist der Fehler weg. Ich habe diesen Fehler unter &lt;a href=&#34;http://www.debian.org/&#34;&gt;Debian&lt;/a&gt; und &lt;a href=&#34;http://xubuntu.org/&#34;&gt;Xubuntu&lt;/a&gt; beobachtet.
Der Fehler scheint &lt;a href=&#34;http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=649408&#34;&gt;dieser Bug&lt;/a&gt; zu sein.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hadoop Cluster und das Netzwerk</title>
      <link>http://localhost:1313/post/2013/05/hadoop-cluster-und-das-netzwerk/</link>
      <pubDate>Tue, 28 May 2013 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2013/05/hadoop-cluster-und-das-netzwerk/</guid>
      <description>&lt;p&gt;Ich habe mich heute wieder mit der Architektur von Hadoop-Clustern beschäftigt. Der Softwarestack ist relativ unspektakulär: Linux -&amp;gt; Java -&amp;gt; &lt;a href=&#34;http://hadoop.apache.org/&#34;&gt;Hadoop&lt;/a&gt;.
Beim Hardware-Stack scheiden sich etwas die Geister. Ich habe immer noch mit dem Gerücht zu kämpfen, dass man für Hadoop &lt;em&gt;Schrott-Rechner&lt;/em&gt;
verwenden kann. Hier wird der Begriff &lt;em&gt;Commodity Hardware&lt;/em&gt; etwas falsch interpretiert. Commodity Hardware bezeichnet im
Hadoop-Kontext keine spezielle Hardware verwendet wird. Große Datenbankensysteme verwenden in der Regel sehr spezielle Hardware.&lt;/p&gt;

&lt;p&gt;Ich beobachte einen Trend, dass es immer mehr &lt;a href=&#34;http://de.wikipedia.org/wiki/Appliance&#34;&gt;Appliances&lt;/a&gt; gibt, welche schon recht spezielle Netzwerktechnik verwenden,
welche man ehr im klassischen HPC mit MPI vermuten würde. Wenn man sich die folgende Frage stellt, dann kommt man schnell
selbst zu der Erkenntnis, dass man auch im Hadoop-Umfeld sehr spezielle Hardware benötigt.&lt;/p&gt;

&lt;p&gt;Ich möchte das ganze einmal an einem Beispiel vorführen: Wenn man in einem Hadoop-Knoten 12 3TB große SAS Platten verbaut,
dann ist es nicht unrealistisch, dass man 120 MB/s von jeder Platte lesen bzw. 100 MB/s schreiben kann und das über einen
längeren Zeitraum. Daraus resultiert eine gesamte Bandbreite von 1440 MB/s bzw. 1200 MB/s. Wenn man sich diese Zahlen ansieht,
dann ergibt es durchaus Sinn 2 10 GBit-Interfaces pro Node zu haben. Wenn man von komprimierten Daten im hdfs ausgeht,
welche unkomprimiert versendet werden, dann können auch 2 QDR &lt;a href=&#34;http://de.wikipedia.org/wiki/InfiniBand&#34;&gt;Infiniband&lt;/a&gt;-Interfaces (40 GBit/s) Sinn. Es gibt durchaus Anbieter,
welche auf Infiniband setzten.&lt;/p&gt;

&lt;p&gt;Durch die Administration und den Ausbau das Hadoop-Clusters meines Arbeitgebers kann ich bestätigen, dass die Daten nicht so lokal
bleiben, wie man es sich das wünschen würde. Das ganze kann sich verschärfen, wenn man im
Cluster noch eine Datenbank, wie &lt;a href=&#34;http://hypertable.com/&#34;&gt;Hypertable&lt;/a&gt; betreibt.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Acrobat Reader für Debian wheezy</title>
      <link>http://localhost:1313/post/2013/05/acrobat-reader-f%C3%BCr-debian-wheezy/</link>
      <pubDate>Mon, 13 May 2013 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2013/05/acrobat-reader-f%C3%BCr-debian-wheezy/</guid>
      <description>&lt;p&gt;Ich hatte heute wieder eine &lt;a href=&#34;http://www.adobe.com/devnet/pdf/pdf_reference.html&#34;&gt;pdf&lt;/a&gt; mit Formularen in,
welche in einen alternativen Viewer nicht wirklich funktioniert hat.
Den Arcobat Reader gibt es leider nicht als 64-Bit Paket, aber die 32-Bit Version tut auch ihren Dienst.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;echo &amp;quot;deb http://www.deb-multimedia.org wheezy main non-free&amp;quot; &amp;gt;&amp;gt; /etc/apt/sources.list
gpg --keyserver pgpkeys.mit.edu --recv-key 07DC563D1F41B907
gpg -a --export 07DC563D1F41B907 | apt-key add -
dpkg --add-architecture i386
apt-get update
apt-get install acroread
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;P.S.: Auf meinen Servern benutze ich &lt;code&gt;/etc/apt/sources.list.d/&amp;lt;listname&amp;gt;.list&lt;/code&gt; für zusätzliche Paketlisten.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Debian wheezy ist stable</title>
      <link>http://localhost:1313/post/2013/05/debian-wheezy-ist-stable/</link>
      <pubDate>Sun, 05 May 2013 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2013/05/debian-wheezy-ist-stable/</guid>
      <description>&lt;p&gt;Seit gestern, den 04.05.2013 ist &lt;a href=&#34;http://www.debian.org/News/2013/20130504&#34;&gt;Debian Wheezy stable&lt;/a&gt;. Nun beginnt die gute Zeit für meine produktiven Systeme. Ich habe schon letzten Sommer einige Systeme auf Wheezy laufen, da ich ein paar Features benötigt habe bzw. haben wollte.&lt;/p&gt;
&lt;p&gt;Ich bin gespannt ob Unschönheiten/Bugs in &lt;a href=&#34;https://www.kernel.org/doc/Documentation/cgroups/cgroups.txt&#34;&gt;cgroups&lt;/a&gt; gefixt wurden. Ich würde gerne mit Hilfe von cgroups die Stabilität eines Hadoop/Hypertable-Clusters erhöhen. Unter Vollast habe ich immer wieder mit partiellen Abstürzen zu kämpfen, was bei zu viel CPU-Last über Memory-Leaks bis zu Timeouts geht, also die gesamte Palette.&lt;/p&gt;
&lt;p&gt;P.S. Das mit dem Bild ist noch nicht vergessen ;-)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Letzte Rettung von MySQL</title>
      <link>http://localhost:1313/post/2011/08/letzte-rettung-von-mysql/</link>
      <pubDate>Mon, 08 Aug 2011 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2011/08/letzte-rettung-von-mysql/</guid>
      <description>&lt;p&gt;
Ich hatte heute wieder Spaß mit &lt;a href=&#34;http://www.mysql.com/&#34;&gt;MySQL&lt;/a&gt;. Die &lt;a href=&#34;http://www.innodb.com/&#34;&gt;InnoDB&lt;/a&gt; Tabelle einer Datenbank hat sich erfolgreich selbst zerstört. Das hat sich dahingehend geäußert, dass sich &lt;a href=&#34;http://www.mysql.com/&#34;&gt;MySQL&lt;/a&gt; immer wieder neu gestartet hat. &lt;a href=&#34;http://www.mysql.com/&#34;&gt;MySQL&lt;/a&gt; war leider nicht in der Lage die betroffene Tabelle selbst wieder her zu stellen.&lt;/p&gt;
&lt;p&gt;
Mit Hilfe von &lt;a href=&#34;http://dev.mysql.com/doc/refman/5.0/en/forcing-innodb-recovery.html&#34;&gt;innodb_force_recovery&lt;/a&gt; kann man MySQL dazu bringen, dass es Tabellen wieder her stellt. Diese Option schreibt man einfach in die &lt;tt&gt;my.cnf&lt;/tt&gt;. Er kann die Werte von 1 bis 6 annehmen. Je höher der Wert ist, desto höher ist die Wahrscheinlichkeit, dass die Tabelle wieder hergestellt werden kann. Aber Achtung: Je größer der Wert ist, desto mehr Daten kann MySQL beim Wiederherstellen zerstören. Es ist deswegen ratsam den Wert inkrementell zu erhöhen, dieses Vorgehen dauert evtl. länger, aber man geht nicht in Gefahr unnötig Daten zu verlieren.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>