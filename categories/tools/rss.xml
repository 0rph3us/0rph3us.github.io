<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tools on Michael im Netz</title>
    <link>https://0rph3us.github.io/categories/tools/</link>
    <description>Recent content in Tools on Michael im Netz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>de-DE</language>
    <copyright>Diese Seite ist unter der &lt;a href=&#34;http://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt; lizenziert.</copyright>
    <lastBuildDate>Wed, 04 Nov 2015 06:55:11 +0100</lastBuildDate>
    <atom:link href="https://0rph3us.github.io/categories/tools/rss/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Einen Jabber Server selbst betreiben</title>
      <link>https://0rph3us.github.io/post/2015/11/einen-jabber-server-selbst-betreiben/</link>
      <pubDate>Wed, 04 Nov 2015 06:55:11 +0100</pubDate>
      
      <guid>https://0rph3us.github.io/post/2015/11/einen-jabber-server-selbst-betreiben/</guid>
      <description>

&lt;p&gt;Am 30.09.2015 war &lt;code&gt;jabber.ccc.de&lt;/code&gt; für &lt;a href=&#34;https://ccc.de/de/updates/2015/jabbercccde&#34;&gt;2 Tage nicht verfügbar&lt;/a&gt;.
Das hat mich motiviert endlich einen eigenen jabber-Server zu
betreiben.&lt;/p&gt;

&lt;p&gt;Hinter Jabber steckt das offene Protokoll &lt;a href=&#34;Extensible Messaging and Presence Protocol&#34;&gt;XMPP&lt;/a&gt;, welches dem
&lt;a href=&#34;https://de.wikipedia.org/wiki/Extensible_Markup_Language&#34;&gt;XML&lt;/a&gt; Standard folgt und für Instant Messaging (Chats) genutzt wird.
Ich habe mich für &lt;a href=&#34;http://prosody.im/&#34;&gt;Prosody&lt;/a&gt; als Jabber-Server entschieden. Für
Prosody sprechen, aus meiner Sicht, seine einefache Konfiguration
sowie seine Schlankheit. Eine Alternatibe ist &lt;a href=&#34;https://www.ejabberd.im/&#34;&gt;ejabberd&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;installation:9cdd19a5faf21f7205a2e96d6a467276&#34;&gt;Installation&lt;/h2&gt;

&lt;p&gt;Damit man Prosody installieren kann, sollte man das Repository
der Entwickler einbinden. Ich nehme auch bei &lt;code&gt;jessie&lt;/code&gt; als
Distribution &lt;code&gt;whezzy&lt;/code&gt;, weil &lt;a href=&#34;https://de.wikipedia.org/wiki/Transport_Layer_Security&#34;&gt;TLS&lt;/a&gt; mit mit den &lt;code&gt;jessie&lt;/code&gt; Paketen
nicht funktioniert.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# zu root werden bzw. sudo vor echo und tee schreiben
echo deb http://packages.prosody.im/debian wheezy main | tee -a /etc/apt/sources.list.d/prosody.list
wget https://prosody.im/files/prosody-debian-packages.key -O- | sudo apt-key add -
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nun kann man Prosody installieren&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;apt-get update &amp;amp;&amp;amp; apt-get install prosody lua-sec-prosody
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Das Paket &lt;code&gt;lua-sec-prosody&lt;/code&gt; wird für TLS benötigt. Wenn man die aktuellste Version
installieren möchte, dann muss man das &lt;code&gt;prosody-0.10&lt;/code&gt; statt &lt;code&gt;prosody&lt;/code&gt; installieren.
Ich habe bis jetzt keine Probleme mit den nighly Builds gehabt.&lt;/p&gt;

&lt;h2 id=&#34;konfiguration:9cdd19a5faf21f7205a2e96d6a467276&#34;&gt;Konfiguration&lt;/h2&gt;

&lt;p&gt;Die Konfiguration wird in &lt;code&gt;/etc/prosody/prosody.cfg.lua&lt;/code&gt; erledigt. Als erstes
In der Zeile &lt;code&gt;admins = { &amp;quot;admin@jabber.0rpheus.net&amp;quot; }&lt;/code&gt; kann gleich
ein entsprechender Admin eingetragen werden. Um zusätzliche User
anzulegen gibt es zwei Möglichkeiten. Entweder direkt über einen
Jabber Client oder auf Zuruf durch einen Administrator. Ersteres
würde bedeuteten, dass sich jeder, der den Server kennt,
registrieren kann. Dazu muss die Zeile &lt;code&gt;allow_registration = false;&lt;/code&gt;
auf &lt;code&gt;allow_registration = true;&lt;/code&gt; geändert werden. Einen Nutzer
legt so an:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;prosodyctl adduser foo@jabber.0rpheus.net
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Als nächstes wird die Domain konfiguriert.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;VirtualHost &amp;quot;jabber.0rpheus.net&amp;quot;
        enabled = true

        -- Assign this host a certificate for TLS, otherwise it would use the one
        -- set in the global section (if any).
        -- Note that old-style SSL on port 5223 only supports one certificate, and will always
        -- use the global one.
        ssl = {
                ciphers     = &amp;quot;AES256+EECDH:AES256+EDH:AES128+EECDH:AES128+EDH&amp;quot;;
                key         = &amp;quot;/etc/prosody/certs/jabber.0rpheus.net.key&amp;quot;;
                certificate = &amp;quot;/etc/prosody/certs/jabber.0rpheus.net.crt&amp;quot;;
                dhparam     = &amp;quot;/etc/prosody/certs/dh-4096.pem&amp;quot;;
                protocol    = &amp;quot;tlsv1_2&amp;quot;;
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Die globalen SSL Einstellungen können entweder entfernt oder
ebenfalls mit denselben Werten nochmal befüllt werden.&lt;/p&gt;

&lt;p&gt;Per Default speichert Prosody die Passwörter im Klartext ab,
um mit alten Clients kompatibel zu sein. Wer das nicht möchte bzw.
nicht braucht, kann die Passwörter gehashed abspeichern.
Dazu muss eine zusätzliche Zeile hinzugefügt werden.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;authentication = &amp;quot;internal_hashed&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Um die Änderungen zu aktivieren, muss der Prosody Dienst
einmal durchgestartet werden.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;systemctl restart prosody
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Folgende Portfreischaltungen werden für einen reibungslosen Betrieb noch benötigt.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Port 5222 eingehend (Clientverbindungen)&lt;/li&gt;
&lt;li&gt;Port 5280 eingehend (Clientverbindungen) (http-bind)&lt;/li&gt;
&lt;li&gt;Port 5281 eingehend (Clientverbindungen) (https-bind)&lt;/li&gt;
&lt;li&gt;Port 5269 ein- und ausgehend Verbindung zu fremden Servern&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Images mit Partionstabellen mounten</title>
      <link>https://0rph3us.github.io/post/2015/10/images-mit-partionstabellen-mounten/</link>
      <pubDate>Thu, 01 Oct 2015 21:27:34 +0200</pubDate>
      
      <guid>https://0rph3us.github.io/post/2015/10/images-mit-partionstabellen-mounten/</guid>
      <description>

&lt;p&gt;Ein Vorteil vom Raspberry Pi ist, dass das Betriebssystem auf einer SD-Karte
ist. Dadurch kann man relativ einfach ein Backup vom gesamten System machen.
Ich gehe davon aus, dass man noch einen weiteren Rechner mit Linux zur
Verfügung hat.&lt;/p&gt;

&lt;p&gt;Ein Backup bietet sich auf jeden Fall an, wenn man ein größeres Update plant
oder ein etwas Experimentiert und viel Software nachinstallieren muss. Im
zweiten Fall kann man schnell sein System verfriemeln und man weiß nicht nicht
mehr was man alles verändert hat.&lt;/p&gt;

&lt;h2 id=&#34;backup-erstellen:f07b0a87c6d8ece6184d80edbd0252a3&#34;&gt;Backup erstellen&lt;/h2&gt;

&lt;p&gt;Am einfachsten kann man ein Backup der kompletten SD-Karte mit &lt;code&gt;dd&lt;/code&gt; machen. Dabei
muss man die Karte in einen zweiten Rechner stecken und heraus finden, wie die SD-Karte heißt.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ lsblk
NAME        MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT
sda           8:0    0 232,9G  0 disk
├─sda1        8:1    0  46,6G  0 part /
└─sda3        8:3    0 186,3G  0 part /home
mmcblk0     179:0    0  14,7G  0 disk
├─mmcblk0p1 179:1    0   256M  0 part
└─mmcblk0p2 179:2    0  14,5G  0 part
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Man sieht, dass das Device für die SD-Karte &lt;code&gt;mmcblk0&lt;/code&gt; ist.
Das andere Device ist meine Festplatte.&lt;/p&gt;

&lt;p&gt;Mit &lt;code&gt;dd&lt;/code&gt; machen wir das eigenliche Backup. Dabei wird der
gesamte Inhalt von &lt;code&gt;/dev/mmcblk0&lt;/code&gt; in die Datei &lt;code&gt;$HOME/backups/pi-backup-$(date +%F).img&lt;/code&gt;
geschrieben. &lt;code&gt;$(date +%F)&lt;/code&gt; fügt das aktuelle Datum in
den Dateinamen ein.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo dd if=/dev/mmcblk0 of=$HOME/backups/pi-backup-$(date +%F).img bs=4096
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nun hat man ein Backup fertig.&lt;/p&gt;

&lt;h2 id=&#34;backup-ansehen:f07b0a87c6d8ece6184d80edbd0252a3&#34;&gt;Backup ansehen&lt;/h2&gt;

&lt;p&gt;Beim Raspberry Pi ist eine Partionstabelle auf der
SD-Karte. Die Daten befinden sich in der 2. Partion.
Diese muss man mounten.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ sudo kpartx $HOME/backups/pi-backup-2015-09-30.img
[sudo] password for rennecke:
loop0p1 : 0 114688 /dev/loop0 8192
loop0p2 : 0 62211072 /dev/loop0 122880
loop deleted : /dev/loop0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nun weiß man, dass die zweite Partion bei Block 62211072
beginnt. Das mounten geht jetzt wie folgt:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo mount -o loop,rw,offset=62914560 $HOME/backups/pi-backup-2015-09-30.img /mnt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ich muss meistens das Abbild beim ersten mal ReadWrite &lt;code&gt;rw&lt;/code&gt; mounten, da das Dateisystem überprüft werden muss.
Sonst kann man auch ReadOnly &lt;code&gt;ro&lt;/code&gt; mounten. Das hat den Vorteil, dass man nichts aus versehen im Backup verändern kann.&lt;/p&gt;

&lt;p&gt;Nachdem man die Partion gemountet hat, kann man mit &lt;code&gt;rsync&lt;/code&gt; oder einfach kopieren einzelne Dateien bzw. ganze Verzeichnisse wieder herstellen. &lt;code&gt;rsync&lt;/code&gt; kann man auch in verbindung mit ssh verwenden.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deterministisches Loadbalancing</title>
      <link>https://0rph3us.github.io/post/2015/09/deterministisches-loadbalancing/</link>
      <pubDate>Thu, 17 Sep 2015 05:58:20 +0200</pubDate>
      
      <guid>https://0rph3us.github.io/post/2015/09/deterministisches-loadbalancing/</guid>
      <description>

&lt;p&gt;Beim Loadbalancing verteilet ein Loadbalancer, wie HAProxy die Last auf mehrere Server. In vielen Fällen macht man das Roud-Robin oder nach Last. Es ergibt auch durchaus Sinn nach einer ID die Backendserver auszuwählen. Daraus ergeben sich zwei Vorteile. Zum einen kann es für Backendserver besser sein, wenn die selbe ID immer auf den selben Server kommt. Dadurch können interene Caches evtl. besser ausgenutzt werden. Da eine ID immer einen Server zugeordnet ist, wird das Loadbalancing deterministisch. Das hat den unschätzbaren Vorteil, dass z.B. eine Anfrage die fehl schlägt immer fehl schlägt.&lt;/p&gt;

&lt;p&gt;Bei meinen Arbeitgeber hatten wir das Problem, dass bestimmte URLs konsequent nicht gehen. Bei einen naiven Test hat der Entwickler festgestellt, dass sein Dienst auf die URL korrekt antwortet. Durch meinen Test der Proxykonfiguration konnte ich ausschließen, dass das Routing im HAProxy Schuld am Fehlverhalten ist. Da dieser Dienst mit einer konsistenten Hashfunktion deterministisch geroutet wird, trat der Fehler immer auf. Dabei stellte sich heraus, dass eine Instanz nicht in der richtigen Version&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:69d192c4ad0750c8f53fe9a830e4a70c:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:69d192c4ad0750c8f53fe9a830e4a70c:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; lief.&lt;/p&gt;

&lt;p&gt;Da Fehler immer wieder vorgekommen, ist es wichtig sie schnell und zuverlässig zu beseitigen. In solchen Situationen ist es besser, den Fehler &lt;strong&gt;immer&lt;/strong&gt; zu haben, anstatt bei jeder x-ten Anfrage.&lt;/p&gt;

&lt;h2 id=&#34;umsetzung-von-deterministischen-loadbalancing:69d192c4ad0750c8f53fe9a830e4a70c&#34;&gt;Umsetzung von deterministischen Loadbalancing&lt;/h2&gt;

&lt;p&gt;Mein favorisierter Loadbalancer für HTTP ist &lt;a href=&#34;http://www.haproxy.org/&#34;&gt;HAProxy&lt;/a&gt;. Ich hatte die Anforderung nach einer ID, welche im Path der URL steht zu balancen. Das ist nicht ganz offensichtlich mit HAProxy. Meine Umsetzung sieht wie folgt aus:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;backend Webserver
        balance hdr(X-MyID)
        hash-type consistent

        http-request set-header     X-MyID %[url]
        http-request replace-header X-MyID ^/foo/bar/lol/([0-9]{5,5}).* \1
        http-request replace-header X-MyID ^/foo/barbar/([0-9]{5,5}).* \1

        server webserver1 10.0.0.1:80
        server webserver2 10.0.0.2:80
        server webserver3 10.0.0.3:80
        server webserver4 10.0.0.4:80
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Als erstes wird die URL in den Header &lt;strong&gt;X-MyID&lt;/strong&gt; kopiert. Die folgenden regulären Ausdrücke schmeißen alles weg, außer die 5-stellige ID. Falls keiner der beiden Ausdrücke angewendet werden kann, steht die URL noch im Header. Dann wird diese als Kriterium für die Verteilung genommen. Der &lt;code&gt;hash-type consistent&lt;/code&gt; bei HAProxy verteilt die Anfragen auf die anderen Server, falls ein Server aus dem Loadbalancing geht.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:69d192c4ad0750c8f53fe9a830e4a70c:1&#34;&gt;Es gab auch schon den Fall, dass eine Instanz auf bestimmte Anfragen nicht beantworten konnte, weil ein Teil der Applikation Ammok lief. Dieser Fehler war auch nicht von außen ersichtlich.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:69d192c4ad0750c8f53fe9a830e4a70c:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>kaputtes System nach Restore mit Obnam</title>
      <link>https://0rph3us.github.io/post/2015/04/kaputtes-system-nach-restore-mit-obnam/</link>
      <pubDate>Mon, 20 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://0rph3us.github.io/post/2015/04/kaputtes-system-nach-restore-mit-obnam/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://obnam.org/&#34;&gt;Obnam&lt;/a&gt; ist ein nettes Backup-Tool, welches ich auf meinen Laptop unter Ubuntu 14.04 verwende.
Ich wollte die Tage einen Restore von einer Datei machen und habe sie inplace wieder herstellen wollen.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo obnam --generation=243130 restore --to=/  /etc/apt/sources.list.d/adiscon-v8-stable-trusty.list
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Danach war meine aktuelle Session im Eimer und ich habe meinen Rechner neu gestartet. Danach gab es eine
große Überraschung: Ich konnte mich nicht mehr einloggen. Nach dem ersten Schreck, dass obnam vielleicht
die Platte geschrottet hat, habe ich mit &lt;a href=&#34;https://grml.org/&#34;&gt;grml&lt;/a&gt; auf die Platte geschaut. Alles war da. Nach einiger Zeit
habe ich festgestellt, dass obnam die Rechte von / auf 700 geändert hat. Nachdem ich / wieder auf 755 geändert
habe ging alles.&lt;/p&gt;

&lt;p&gt;Es ist leider reproduzierbar, dass obnam die Rechte alle Verzechnisse beim Restore kaputt macht, welche
es nicht unter Kontrolle hat. Aus diesem Grund mache ich einen Restore jetzt wie folgt:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo obnam --generation=243130 restore --to=/home/rennecke/restore  /etc/apt/sources.list.d/adiscon-v8-stable-trusty.list
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Das aktuelle Verhalten ist ein absolutes No-Go! Ich verwende die Version 1.9 aus &lt;a href=&#34;https://launchpad.net/~chris-bigballofwax/+archive/ubuntu/obnam-ppa&#34;&gt;dieser PPA&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Modernes Logging Teil 2</title>
      <link>https://0rph3us.github.io/post/2015/02/modernes-logging-teil-2/</link>
      <pubDate>Tue, 24 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://0rph3us.github.io/post/2015/02/modernes-logging-teil-2/</guid>
      <description>

&lt;p&gt;Ich habe in meinen &lt;a href=&#34;https://0rph3us.github.io/post/2015/02/modernes-logging/&#34;&gt;letzten Beitrag über Logging&lt;/a&gt; schon geschrieben, wie man eine moderne Logging-Infrastruktur aufsetzten kann.
Inzwischen wurde &lt;a href=&#34;http://www.elasticsearch.org/overview/kibana/&#34;&gt;Kibana&lt;/a&gt; in der Version 4 finale freigegeben. In diesem Artikel möchte ich das Upgrade auf die
finale Version zeigen und auf das &lt;a href=&#34;http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/setup-repositories.html&#34;&gt;Repository von Elasticsearch&lt;/a&gt; hinweisen.&lt;/p&gt;

&lt;p&gt;Kibana in der finalen Version 4 lässt sich genauso installieren, wie der Release Candidate. Man muss nur die Konfiguration
im Elasticsearch anpassen.&lt;/p&gt;

&lt;h3 id=&#34;vorarbeiten:568e9c6fc3669f1cee0d24068e094cd2&#34;&gt;Vorarbeiten&lt;/h3&gt;

&lt;p&gt;Als erstes fährt man Kibana herunter und updatet Elasricsearch auf die Version 1.4.4. Das geht sehr einfach, wenn man das
entsprechende &lt;a href=&#34;http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/setup-repositories.html&#34;&gt;Repository&lt;/a&gt; benutzt. Dann ist es nur noch ein &lt;code&gt;apt-get install elasticsearch&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;update-auf-kibana-4:568e9c6fc3669f1cee0d24068e094cd2&#34;&gt;Update auf Kibana 4&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;wget https://download.elasticsearch.org/kibana/kibana/kibana-4.0.0-linux-x64.tar.gz
tar xfvz kibana-4.0.0-linux-x64.tar.gz

# Index updaten
BODY=`curl -XGET &#39;localhost:9200/.kibana/config/4.0.0-rc1/_source&#39;`; curl -XPUT &amp;quot;localhost:9200/.kibana/config/4.0.0&amp;quot; -d &amp;quot;$BODY&amp;quot; &amp;amp;&amp;amp; curl -XDELETE &amp;quot;localhost:9200/.kibana/config/4.0.0-rc1&amp;quot;

# kibana starten
kibana-4.0.0-linux-x64/bin/kibana
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;nachtrag-06-03-2015:568e9c6fc3669f1cee0d24068e094cd2&#34;&gt;Nachtrag 06.03.2015&lt;/h3&gt;

&lt;p&gt;Es wurde &lt;a href=&#34;https://www.elasticsearch.org/blog/kibana-4-0-1-released/&#34;&gt;Kibana 4.0.1&lt;/a&gt; released. Diese Version hat ein paar Bugfixes und man auch den Index nicht updaten, wenn man den Release Candidate noch installiert hat.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Modernes Logging</title>
      <link>https://0rph3us.github.io/post/2015/02/modernes-logging/</link>
      <pubDate>Sun, 15 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://0rph3us.github.io/post/2015/02/modernes-logging/</guid>
      <description>

&lt;p&gt;Achtung: Es gibt einen &lt;a href=&#34;https://0rph3us.github.io/post/2015/02/modernes-logging-teil-2/&#34;&gt;2. Teil des Artikels&lt;/a&gt;, welchen sich vorher ansehen solle, bevor man hier alles copy&amp;amp;pastet&lt;/p&gt;

&lt;p&gt;In &lt;a href=&#34;http://de.wikipedia.org/wiki/Java_%28Programmiersprache%29&#34;&gt;Java&lt;/a&gt;-Welt ist folgende Stack für Logging recht verbreitet, weil man mit ihm ein leistungsstarkes modernes und zentrales Logging umsetzten kann. Dieser Stack besteht aus &lt;a href=&#34;http://www.elasticsearch.org/&#34;&gt;Elasticsearch&lt;/a&gt;, einen Volltextindex zum speichern der Nahrichten. Diese werden von &lt;a href=&#34;http://logstash.net/&#34;&gt;Logstash&lt;/a&gt; verarbeitet und zum Index geschickt. &lt;a href=&#34;http://www.elasticsearch.org/overview/kibana/&#34;&gt;Kibana&lt;/a&gt; wird zum
visualisieren der Volltextinhalte genommen. Ich finde Logstash zum reinen verschicken von Lognahrichten zu schwergewichtig und es bötigt zu viel Ressourcen. Linux verwendet &lt;a href=&#34;http://de.wikipedia.org/wiki/Syslog&#34;&gt;syslog&lt;/a&gt; zum versenden von Lognachrichten. In vieles Distributionen wird &lt;a href=&#34;http://www.rsyslog.com/&#34;&gt;rsyslog&lt;/a&gt; zum verarbeiten der Nahrichten verwendet. Das gute ist, dass man mit rsyslog auch direkt in Elasticsearch loggen kann. So kann man mit rsyslog, Elasticsearch und Kibana ein leichtgewichtigeres und modernes Logsystem bauen.&lt;/p&gt;

&lt;p&gt;Die folgende Anleitung beschreibt, wie man das ganze unter Ubuntu 14.04 einrichtet. Ich beschreibe kein komplettes Setup, es ist als Einstieg in die Thematik gedacht.&lt;/p&gt;

&lt;h3 id=&#34;rsyslog-unter-ubuntu-14-04-installieren:0f1926dffb36411c33c28d4643e7a8d5&#34;&gt;rsyslog unter Ubuntu 14.04 installieren&lt;/h3&gt;

&lt;p&gt;Eine Konsole öffnen und das Repository hinzufügen. Es handelt sich hierbei um das &lt;a href=&#34;http://www.rsyslog.com/ubuntu-repository/&#34;&gt;offizelle Repository&lt;/a&gt; von rsyslog. Rsyslog ist in den offizellen Repositories von Ubuntu nicht auf dem neusten Stand, außerdem gibt kein Paket mit dem Elasticsearchsupport.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo add-apt-repository ppa:adiscon/v8-stable
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Den Cache von &lt;code&gt;apt&lt;/code&gt; aktualisieren und &lt;code&gt;rsyslog&lt;/code&gt; mit der Elasticsearch Unterstützung installieren&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo apt-get update
sudo apt-get install rsyslog rsyslog-elasticsearch
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;elasticsearch-installieren:0f1926dffb36411c33c28d4643e7a8d5&#34;&gt;Elasticsearch installieren&lt;/h3&gt;

&lt;p&gt;deb-Paket herunterladen und installieren. Die Installation über das deb-Paket hat den Vorteil, dass man Elasticsearch einfach updaten kann und es gibt auch schon init-Skripte.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;wget https://download.elasticsearch.org/elasticsearch/elasticsearch/elasticsearch-1.4.3.deb
sudo dpkg -i elasticsearch-1.4.3.deb
sudo update-rc.d elasticsearch defaults
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Elasticsearch konfigurieren. Dazu muss man die Datei &lt;code&gt;/etc/elasticsearch/elasticsearch.yml&lt;/code&gt; im Editor seine Wahl öffnen und die folgenden Zeilen einkommentieren und ändern&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# Set the number of shards (splits) of an index (5 by default):
#
index.number_of_shards: 1

# Set the number of replicas (additional copies) of an index (1 by default):
#
index.number_of_replicas: 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Elasticsearch starten:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo service elasticsearch start
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;rsyslog-konfigurieren:0f1926dffb36411c33c28d4643e7a8d5&#34;&gt;rsyslog konfigurieren&lt;/h3&gt;

&lt;p&gt;Man muss nun dafür sorgen, dass die Lognahrichten von rsyslog nach Elasticsearch geschrieben werden. Als erstes legt man ein &lt;a href=&#34;http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping.html&#34;&gt;Mapping&lt;/a&gt; in Elasticsearch an. Damit sagt man Elasticsearch, dass es das Feld &lt;code&gt;program&lt;/code&gt; &lt;a href=&#34;http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-core-types.html&#34;&gt;nicht analysieren&lt;/a&gt; soll. Außerdem sollen die Dokumente nach &lt;a href=&#34;http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-ttl-field.html&#34;&gt;90 Tagen gelöscht&lt;/a&gt; werden.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -XPUT &#39;http://localhost:9200/logstash&#39; -d &#39;{
  &amp;quot;mappings&amp;quot;: {
    &amp;quot;events&amp;quot; : {
      &amp;quot;_ttl&amp;quot; : {
        &amp;quot;enabled&amp;quot; : true,
        &amp;quot;default&amp;quot; : &amp;quot;90d&amp;quot;
        },
      &amp;quot;properties&amp;quot; : {
        &amp;quot;program&amp;quot; : {
          &amp;quot;type&amp;quot; : &amp;quot;string&amp;quot;,
          &amp;quot;index&amp;quot; : &amp;quot;not_analyzed&amp;quot;,
          &amp;quot;norms&amp;quot; : {
            &amp;quot;enabled&amp;quot; : false
          }
        }
      }
    }
  }
}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nach man die Datei  &lt;code&gt;/etc/rsyslog.d/30-elasticsearch.conf&lt;/code&gt; erstellt hat, muss
man nur noch &lt;code&gt;rsyslog&lt;/code&gt; neu starten. Wenn es Probleme gibt kann man mit &lt;code&gt;rsyslogd -N1&lt;/code&gt; die Konfiguraion überprüfen.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo su -
cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/rsyslog.d/30-elasticsearch.conf
#module(load=&amp;quot;imuxsock&amp;quot;)       # for listening to /dev/log, normal not needed
module(load=&amp;quot;omelasticsearch&amp;quot;) # for outputting to Elasticsearch

# this is for index names to be like: logstash-YYYY.MM.DD
template(name=&amp;quot;logstash-index&amp;quot;
  type=&amp;quot;list&amp;quot;) {
    constant(value=&amp;quot;logstash-&amp;quot;)
    property(name=&amp;quot;timereported&amp;quot; dateFormat=&amp;quot;rfc3339&amp;quot; position.from=&amp;quot;1&amp;quot; position.to=&amp;quot;4&amp;quot;)
    constant(value=&amp;quot;.&amp;quot;)
    property(name=&amp;quot;timereported&amp;quot; dateFormat=&amp;quot;rfc3339&amp;quot; position.from=&amp;quot;6&amp;quot; position.to=&amp;quot;7&amp;quot;)
    constant(value=&amp;quot;.&amp;quot;)
    property(name=&amp;quot;timereported&amp;quot; dateFormat=&amp;quot;rfc3339&amp;quot; position.from=&amp;quot;9&amp;quot; position.to=&amp;quot;10&amp;quot;)
}

# use only one index, useful only for local usage
template(name=&amp;quot;logstash&amp;quot; type=&amp;quot;string&amp;quot; string=&amp;quot;logstash&amp;quot;)

# this is for formatting our syslog in JSON with @timestamp
template(name=&amp;quot;plain-syslog&amp;quot;
  type=&amp;quot;list&amp;quot;) {
    constant(value=&amp;quot;{&amp;quot;)
      constant(value=&amp;quot;\&amp;quot;@timestamp\&amp;quot;:\&amp;quot;&amp;quot;)     property(name=&amp;quot;timereported&amp;quot; dateFormat=&amp;quot;rfc3339&amp;quot;)
      constant(value=&amp;quot;\&amp;quot;,\&amp;quot;host\&amp;quot;:\&amp;quot;&amp;quot;)        property(name=&amp;quot;hostname&amp;quot;)
      constant(value=&amp;quot;\&amp;quot;,\&amp;quot;severity\&amp;quot;:\&amp;quot;&amp;quot;)    property(name=&amp;quot;syslogseverity-text&amp;quot;)
      constant(value=&amp;quot;\&amp;quot;,\&amp;quot;facility\&amp;quot;:\&amp;quot;&amp;quot;)    property(name=&amp;quot;syslogfacility-text&amp;quot;)
      constant(value=&amp;quot;\&amp;quot;,\&amp;quot;tag\&amp;quot;:\&amp;quot;&amp;quot;)         property(name=&amp;quot;syslogtag&amp;quot; format=&amp;quot;json&amp;quot;)
      constant(value=&amp;quot;\&amp;quot;,\&amp;quot;program\&amp;quot;:\&amp;quot;&amp;quot;)     property(name=&amp;quot;programname&amp;quot;)
      constant(value=&amp;quot;\&amp;quot;,\&amp;quot;message\&amp;quot;:\&amp;quot;&amp;quot;)     property(name=&amp;quot;msg&amp;quot; format=&amp;quot;json&amp;quot;)
    constant(value=&amp;quot;\&amp;quot;}&amp;quot;)
}

# this is where we actually send the logs to Elasticsearch (localhost:9200 by default)
action(type=&amp;quot;omelasticsearch&amp;quot;
    template=&amp;quot;plain-syslog&amp;quot;
    searchIndex=&amp;quot;logstash&amp;quot;
    dynSearchIndex=&amp;quot;on&amp;quot;)

EOF
/etc/init.d/rsyslog restart
exit
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;kibana-installieren:0f1926dffb36411c33c28d4643e7a8d5&#34;&gt;Kibana installieren&lt;/h3&gt;

&lt;p&gt;Für Kibana gibt es leider keinen bequemen Installationsweg. Deswegen beschreibe ich den Weg, der schnell und einfach zum Ziel führt, aber auf keinen Fall sinnvoll für den produktiven Betrieb ist. Man läd Kibana herunter und startet es.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;wget https://download.elasticsearch.org/kibana/kibana/kibana-4.0.0-rc1-linux-x64.tar.gz
tar xfvz kibana-4.0.0-rc1-linux-x64.tar.gz
kibana-4.0.0-rc1-linux-x64/bin/kibana
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nun kann man auf Kibana über &lt;code&gt;http://127.0.0.1:5601/&lt;/code&gt; im Browser zugreifen. Man muss nur noch Kibana sagen, welchen Index es benutzen soll. Das geht realtiv intuitiv.&lt;/p&gt;

&lt;h3 id=&#34;anmerkung:0f1926dffb36411c33c28d4643e7a8d5&#34;&gt;Anmerkung&lt;/h3&gt;

&lt;p&gt;Das es rsyslog auch für Windows gibt, kann man diesen Stack auch für Windows nutzen. Ich habe hier alle Technologien nur angeschitten, für ein richtiges Setup muss man noch viel mehr beachten und konfigurieren.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Skripte parallelisieren</title>
      <link>https://0rph3us.github.io/post/2015/02/skripte-parallelisieren/</link>
      <pubDate>Thu, 12 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://0rph3us.github.io/post/2015/02/skripte-parallelisieren/</guid>
      <description>

&lt;p&gt;Für viele Aufgaben bei meiner täglichen Arbeit mit Linux nutze ich &lt;a href=&#34;http://tiswww.case.edu/php/chet/bash/bashtop.html&#34;&gt;bash&lt;/a&gt;-Skripte bzw. tippe sie gleich auf der Komandozeile ein. Es gibt viele Aufgaben welche &lt;em&gt;langwierig&lt;/em&gt; sind und leicht parallelisierbar sind. Hier kann das Programm &lt;a href=&#34;http://www.gnu.org/software/parallel/&#34;&gt;parallel&lt;/a&gt; helfen. Im einfachsten Fall stellt man es sich wie eine Art Queueing-System vor. Die Aufgabenpakete werden in eine Warteschlange gesteckt und &lt;code&gt;n&lt;/code&gt; Prozesse arbeiten die Warteschlange ab. Wenn man nichts konfiguriert, dann ist &lt;code&gt;n&lt;/code&gt; die Anzahl der Prozessorkerne.&lt;/p&gt;

&lt;p&gt;Man kann &lt;code&gt;parallel&lt;/code&gt; als Ersatz für &lt;code&gt;xargs&lt;/code&gt; nehmen oder um Schleifen zu parallelisieren. Auf der Seite von &lt;code&gt;parallel&lt;/code&gt; gibt es viele &lt;a href=&#34;http://www.gnu.org/software/parallel/man.html&#34;&gt;Beispiele&lt;/a&gt;, welche über das parallelisieren von Schleifen hinaus gehen.&lt;/p&gt;

&lt;h3 id=&#34;aktueller-anwendungsfall:cb1bfcf9cf27c64f5ffffa51a1dd92e0&#34;&gt;Aktueller Anwendungsfall&lt;/h3&gt;

&lt;p&gt;Ich nutze &lt;code&gt;parallel&lt;/code&gt; zum erstellen von Backups. Dazu kopiere ich sehr viele kleine Dateien auf eine &lt;a href=&#34;http://de.wikipedia.org/wiki/Network_File_System&#34;&gt;NFS&lt;/a&gt;-Freigabe. Ich habe &lt;a href=&#34;http://rsync.samba.org/&#34;&gt;rsync&lt;/a&gt; und &lt;code&gt;cp&lt;/code&gt; probiert. &lt;code&gt;rsync&lt;/code&gt; ist in meinen Fall langsamer als &lt;code&gt;cp&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Aus diesem Grund habe ich &lt;code&gt;cp&lt;/code&gt;, wie folgt parallelisiert:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;find . -type f -mtime -2 | parallel --jobs 16 /usr/sbin/backup_helper.sh {}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Es werden alle Dateien gesucht, welche jünger als 2 Tage sind. Diese werden mit 16 parallelen &lt;code&gt;cp&lt;/code&gt; auf das NFS-Share kopiert. So bekomme meine 1GBit Netzwerkanbindung während des Backups ausgelastet. Beim sequenziellen kopieren bzw. mit &lt;code&gt;rsync&lt;/code&gt; bin ich nicht über 100MBit/s gekommen.&lt;/p&gt;

&lt;p&gt;Das script &lt;code&gt;backup_helper.sh&lt;/code&gt; sieht wie folgt aus:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cat /usr/sbin/backup_helper.sh
#!/bin/bash

base=&amp;quot;$(dirname ${1})&amp;quot;
mkdir -p &amp;quot;/backup/${base}&amp;quot;
cp &amp;quot;${1}&amp;quot; &amp;quot;/backup/${1}&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>rrdtool und json</title>
      <link>https://0rph3us.github.io/post/2014/10/rrdtool-und-json/</link>
      <pubDate>Tue, 28 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>https://0rph3us.github.io/post/2014/10/rrdtool-und-json/</guid>
      <description>&lt;p&gt;In den letzten beiden Beiträgen habe ich erklärt, wie man den &lt;a href=&#34;https://0rph3us.github.io/post/2014/10/dht22-am-raspberry-pi/&#34;&gt;DTH22&lt;/a&gt; bzw. &lt;a href=&#34;https://0rph3us.github.io/post/2014/10/bmp085-am-raspberry-pi/&#34;&gt;BMP085&lt;/a&gt; am
Raspberry Pi betreibt. Es liegt nahe die Sensordaten aufzuzeichnen und zu
visualisieren. In einen kleinen Prototyp habe ich die Daten mit &lt;a href=&#34;http://oss.oetiker.ch/rrdtool/&#34;&gt;RRDtool&lt;/a&gt; gespeichert und mit &lt;a href=&#34;http://www.highcharts.com/&#34;&gt;Highcharts&lt;/a&gt;
angezeigt.&lt;/p&gt;

&lt;p&gt;Meine Idee war, dass ich aus der RRD-Datenbank einige Daten zu json konvertiere, um sie dann
mit Highcharts anzuzeigen. Die json-Daten wollte ich mit einem ajax-Request nachladen. Da ich
so gut wie keine JavaScript- und JQuerry-Kenntnisse habe, habe ich sehr lange vergeblich
probiert einen Graph zu zeichnen. Als ich das von RRDtool generierte &amp;ldquo;json&amp;rdquo; mir angesehen
habe, ist mir aufgefallen, dass es kein valides json ist&amp;hellip;&lt;/p&gt;

&lt;p&gt;Weil ich noch ein Erfolgserlebnis haben wollte, bin ich auf den validen xml-Export von
RRDtool umgestiegen. Danach hat der Prototyp funktioniert.&lt;/p&gt;

&lt;p&gt;Nach etwas Recherche im Netz, bin ich auch auf ein &lt;a href=&#34;https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=686825&#34;&gt;Bug-Ticket&lt;/a&gt; gestoßen, welches den kaputten
json-Export anspricht.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Neuer Blog</title>
      <link>https://0rph3us.github.io/post/2014/07/neuer-blog/</link>
      <pubDate>Thu, 17 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>https://0rph3us.github.io/post/2014/07/neuer-blog/</guid>
      <description>

&lt;p&gt;Ich habe mich entschlossen, meinen alten &lt;a href=&#34;http://wpde.org/&#34;&gt;Wordpress&lt;/a&gt;-Blog einzudampfen. Ich
fand Wordpress schon immer recht schwergewichtig, aber ich kannte bis jetzt keine Alternative um einen
&amp;ldquo;gut&amp;rdquo; aussehenden Blog mit &amp;ldquo;wenig&amp;rdquo; Arbeit zu pflegen.&lt;/p&gt;

&lt;p&gt;Nun bin ich auf &lt;a href=&#34;http://jekyllbootstrap.com&#34;&gt;JekyllBootstrap&lt;/a&gt; und &lt;a href=&#34;https://github.com/dhulihan/hooligan&#34;&gt;Hooligan&lt;/a&gt; gestoßen.
Am Theme habe ich etwas etwas Hand angelegt. Als
Versionsverwaltung nutze ich &lt;a href=&#34;http://git-scm.com/&#34;&gt;git&lt;/a&gt;. Der gesamte Blog ist als
Code auf &lt;a href=&#34;https://github.com/0rph3us/jekyll-bootstrap&#34;&gt;github&lt;/a&gt; zu finden.&lt;/p&gt;

&lt;p&gt;Da ich nun offline am Blog arbeiten kann, möchte ich wieder aktiver sein.&lt;/p&gt;

&lt;h2 id=&#34;der-alte:35e6c4eaf33501dfb90b608aab77ae63&#34;&gt;Der Alte&lt;/h2&gt;

&lt;p&gt;Ich habe bzw. bin noch dabei die gesamten Inhalte des alten Wordpress zu portieren. Das meiste habe
ich automatisch migriert. Dadurch kann es noch Leichen im Layout geben. Ich werde nach und nach
die alten Posts überarbeiten.&lt;/p&gt;

&lt;h2 id=&#34;technik:35e6c4eaf33501dfb90b608aab77ae63&#34;&gt;Technik&lt;/h2&gt;

&lt;p&gt;Die erste Version des Blogs wird auf meinen Raspberry Pi laufen. Als Webserver verwende ich Nginx, außerdem
verwende ich Varnish zum cachen. Ich hoffe, dass mit diesem Setup die Geschwindigkeit des Blog
erträglich bleibt.&lt;/p&gt;

&lt;p&gt;In weiteren Beiträgen werde ich schreiben wie das Setup genau aussieht. Ich auch noch etwas
am ausprobieren.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Neuer GPG-Key</title>
      <link>https://0rph3us.github.io/post/2013/09/neuer-gpg-key/</link>
      <pubDate>Mon, 09 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://0rph3us.github.io/post/2013/09/neuer-gpg-key/</guid>
      <description>&lt;p&gt;Nach den ganzen &lt;a href=&#34;http://www.nsa.gov/&#34;&gt;NSA&lt;/a&gt;-Enthüllungen, habe ich mich wieder mit Public-Key-Kryptografie beschäftigt. Mein bisheriger &lt;a href=&#34;http://www.gnupg.org/&#34;&gt;GPG&lt;/a&gt;-Schüssel D12E87BA hat &lt;a href=&#34;http://www.itl.nist.gov/fipspubs/fip186.htm&#34;&gt;DSA&lt;/a&gt; und &lt;a href=&#34;http://de.wikipedia.org/wiki/Elgamal-Verschl%C3%BCsselungsverfahren&#34;&gt;ElGamal&lt;/a&gt; verwendet. Ich habe damals diese Algorithmen damals gewählt, da ich keinen &#34;Standard-Key&#34; haben wollte. Die Längen sind auch nach heutigen Maßstäben ausreichend. Es aber &lt;a href=&#34;http://rdist.root.org/2010/11/19/dsa-requirements-for-random-k-value/&#34;&gt;Angriffe für DSA&lt;/a&gt;, welche darauf beruhen, dass die Zufallszahlen von Zufallszahlengeneratoren nicht zufällig sind. Da ich meinen Schlüssel auf beliebigen Rechnern und auch Endgeräten nutzen möchte, kann ich nicht immer sicher stellen, dass der Zufallszahlengenerator wirklich korrekt seine Arbeit macht. Aus diesem Grund habe ich mir ein neues Schlüsselpaar mit &lt;a href=&#34;http://de.wikipedia.org/wiki/RSA-Kryptosystem&#34;&gt;RSA&lt;/a&gt; zum verschlüsseln und signieren erstellt.&lt;/p&gt;
&lt;p&gt;Es ist nicht ganz unwahrscheinlich, dass &lt;a href=&#34;http://news.cnet.com/8301-13578_3-57591560-38/facebooks-outmoded-web-crypto-opens-door-to-nsa-spying/&#34;&gt;große Organisationen 1024 Bit RSA Schüssel faktorisieren&lt;/a&gt; können. Ein Schlüssellänge von 2048 Bit gilt als sicher und 4096 Bit als paranoid. Ich bin lieber paranoid und nehme 4096 lange Schlüssel, da diese Schüssellänge auf heutigen Rechnern kein Problem darstellt und von fast allen Implementieren von GPG unterstützt wird.&lt;/p&gt;
&lt;p&gt;Mein neuer Key ist &lt;a href=&#34;http://pgp.mit.edu:11371/pks/lookup?op=vindex&amp;amp;search=0x617EB806EE75C6FE&#34;&gt;EE75C6FE&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Letzte Rettung von MySQL</title>
      <link>https://0rph3us.github.io/post/2011/08/letzte-rettung-von-mysql/</link>
      <pubDate>Mon, 08 Aug 2011 00:00:00 +0000</pubDate>
      
      <guid>https://0rph3us.github.io/post/2011/08/letzte-rettung-von-mysql/</guid>
      <description>&lt;p&gt;
Ich hatte heute wieder Spaß mit &lt;a href=&#34;http://www.mysql.com/&#34;&gt;MySQL&lt;/a&gt;. Die &lt;a href=&#34;http://www.innodb.com/&#34;&gt;InnoDB&lt;/a&gt; Tabelle einer Datenbank hat sich erfolgreich selbst zerstört. Das hat sich dahingehend geäußert, dass sich &lt;a href=&#34;http://www.mysql.com/&#34;&gt;MySQL&lt;/a&gt; immer wieder neu gestartet hat. &lt;a href=&#34;http://www.mysql.com/&#34;&gt;MySQL&lt;/a&gt; war leider nicht in der Lage die betroffene Tabelle selbst wieder her zu stellen.&lt;/p&gt;
&lt;p&gt;
Mit Hilfe von &lt;a href=&#34;http://dev.mysql.com/doc/refman/5.0/en/forcing-innodb-recovery.html&#34;&gt;innodb_force_recovery&lt;/a&gt; kann man MySQL dazu bringen, dass es Tabellen wieder her stellt. Diese Option schreibt man einfach in die &lt;tt&gt;my.cnf&lt;/tt&gt;. Er kann die Werte von 1 bis 6 annehmen. Je höher der Wert ist, desto höher ist die Wahrscheinlichkeit, dass die Tabelle wieder hergestellt werden kann. Aber Achtung: Je größer der Wert ist, desto mehr Daten kann MySQL beim Wiederherstellen zerstören. Es ist deswegen ratsam den Wert inkrementell zu erhöhen, dieses Vorgehen dauert evtl. länger, aber man geht nicht in Gefahr unnötig Daten zu verlieren.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>noSQL Datenbanken</title>
      <link>https://0rph3us.github.io/post/2011/05/nosql-datenbanken/</link>
      <pubDate>Wed, 18 May 2011 00:00:00 +0000</pubDate>
      
      <guid>https://0rph3us.github.io/post/2011/05/nosql-datenbanken/</guid>
      <description>&lt;p&gt;
Ich arbeite inzwischen bei &lt;a href=&#34;http://www.unister.de/&#34;&gt;Unister&lt;/a&gt; als &lt;a href=&#34;http://0rpheus.net/privat/junior-system-architekt&#34;&gt;Junior Systemarchitekt&lt;/a&gt;. Zu meinen ersten Aufgaben hat gezählt eine Architektur für eine eine Datenbank zu schaffen, welche mit sehr hohen Schreibaufkommen zurecht kommt. Als Datenbank haben wir &lt;a href=&#34;http://www.mongodb.org/&#34;&gt;mongoDB&lt;/a&gt; benutzt. Dabei handelt es sich um eine &lt;a href=&#34;http://nosql-database.org/&#34;&gt;noSQL&lt;/a&gt;-Datenbank. Diese Dazenbanken haben kein festes Datenbankschema.&lt;/p&gt;
&lt;p&gt;
Die ersten Ergebnisse waren sehr erschütternd. Die Schreibperformence war einfach zu gering. Da man bei &lt;a href=&#34;http://www.mongodb.org/&#34;&gt;mongoDB&lt;/a&gt; nichts konfigurieren kann (Im Vergleich zu klassischen Datenbanken, wie MySQL oder PostgreSQL) war ich erst einmal ratlos. Das ganze konnte mit Clustern nicht verbessert werden. Eine genaue Untersuchung der Applikation hat ergeben, dass die Daten synchron und damit blockierend geschrieben wurden. Nachdem die Inserts nicht blockierend und in Batches umgesetzt wurden konnte schon ein Performancesprung festgestellt werden. Das konnte weiter verbessert werden, als wir die einzufügenden Daten in der Applikation nach dem Index vorsortiert eingefügt haben. Die Ursache liegt darin, das die Datenbank den Batch schneller abarbeiten kann und weniger Operationen auf dem Index nötig sind.&lt;/p&gt;
&lt;p&gt;
Zum Schluss möchte ich noch ein paar Worte zum Clustern von &lt;a href=&#34;http://www.mongodb.org/&#34;&gt;mongoDB&lt;/a&gt; verlieren. Es wird alles mitgebracht um schnell einen Cluster aufzusetzten. Ich habe es es leider geschafft, durch den Absturz von einem Knoten, den gesamten Cluster zu zerstören. Also sollte man bei Wichtigen Daten für Redundanz im Cluster sorgen. Es gibt auch viele Mittel in mongoDB um diese Redundanz zu erreichen.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mercurial</title>
      <link>https://0rph3us.github.io/post/2011/02/mercurial/</link>
      <pubDate>Tue, 22 Feb 2011 00:00:00 +0000</pubDate>
      
      <guid>https://0rph3us.github.io/post/2011/02/mercurial/</guid>
      <description>&lt;p&gt;Ich wollte eben, mal schnell ein &lt;a href=&#34;http://mercurial.selenic.com/&#34;&gt;Mercurial&lt;/a&gt;-Repository einen Bekannten zur Verfügung stellen. Also habe ich es auf seinen Server kopiert. Nun kam die Überraschung: Es ging nicht mehr. Es gibt die typischen dubiosen Fehlermeldungen von &lt;a href=&#34;http://mercurial.selenic.com/&#34;&gt;Mercurial&lt;/a&gt;, bei denen niemand weiß was los ist. Da ich schon sehr lange unter Solaris mit &lt;a href=&#34;http://mercurial.selenic.com/&#34;&gt;Mercurial&lt;/a&gt; arbeite kenne ich so ein paar Fallstricke.&lt;/p&gt;
&lt;p&gt;In diesem Fall war die &lt;a href=&#34;http://mercurial.selenic.com/&#34;&gt;Mercurial&lt;/a&gt;-Versionen verschieden. In vielen Fällen, kann man das wie folgt beheben:&lt;/p&gt;
&lt;pre lang=&#34;bash&#34;&gt;
# remote-Server
rennecke@odin /export/repos % hg init newrepo
# local host
rennecke@walhalla ~/repo (hg)-[default] % hg push ssh://rennecke@odin//export/repos/newrepo
&lt;/pre&gt;
&lt;p&gt;
Nachdem man auf dem Server ein leeren Repo angelegt hat, kann man die Inhalte rein pushen. Wenn man hinter einem Proxy-Server ist, kann man diesen gleich mit angeben:&lt;/p&gt;
&lt;pre lang=&#34;bash&#34;&gt;
rennecke@trantor ~ % hg --config http_proxy.host=my-proxy.org:3128 clone  ssh://rennecke@odin//export/repos/newrepo
&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Tree Tab Style bei Firefox</title>
      <link>https://0rph3us.github.io/post/2011/01/tree-tab-style-bei-firefox/</link>
      <pubDate>Sat, 08 Jan 2011 00:00:00 +0000</pubDate>
      
      <guid>https://0rph3us.github.io/post/2011/01/tree-tab-style-bei-firefox/</guid>
      <description>&lt;p&gt;Ich nutze schon sehr lange den &lt;a href=&#34;https://addons.mozilla.org/en-US/firefox/addon/5890/&#34;&gt;Tree Tab Style&lt;/a&gt; für Firefox. Heute ist mein Firefox unter Solaris alle 3 Minuten abgestürzt. Bis ich auf die Idee gekommen bin, dass es evtl. mein&lt;a href=&#34;https://addons.mozilla.org/en-US/firefox/addon/5890/&#34;&gt; Tree Tab Style Plugin&lt;/a&gt; ist. Der Firefox hat gemeint, dass es kein Update gibt. Also habe ich auf der &lt;a href=&#34;http://piro.sakura.ne.jp/xul/_treestyletab.html.en#download&#34;&gt;Projektseite des Entwickler&lt;/a&gt; nachgeschaut und dort gab es ein Update. Dieses funktioniert. Ob dieser Fehler nur bei Solaris auftritt weiß ich nicht.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Im SunStudio die STL nutzen</title>
      <link>https://0rph3us.github.io/post/2010/11/im-sunstudio-die-stl-nutzen/</link>
      <pubDate>Fri, 26 Nov 2010 00:00:00 +0000</pubDate>
      
      <guid>https://0rph3us.github.io/post/2010/11/im-sunstudio-die-stl-nutzen/</guid>
      <description>&lt;p&gt;Mir ist die Tage beim programmieren negativ aufgefallen, dass sich im  Sun Studio 12 Express einige Funktionen anderst sind, als in der STL  spezifiziert. Mir ist es bei &lt;em&gt;std::sort&lt;/em&gt; aufgefallen. Man kann normal &lt;em&gt;sort&lt;/em&gt; eine Funktion übergeben, welche die Elemente vergleicht. Diese  Überladung existiert in der Sun STL nicht. Das ist bekannt und wurde  schon an anderen Stellen diskutiert. Wenn man die STL nutzen möchte,  dann muss man dem Compiler die Option &lt;em&gt;-library=stlport4&lt;/em&gt; mitgeben, dann  wird die standartkonforme STL verwendet.&lt;/p&gt;
&lt;p&gt;Im Sun Studio kann man diese Option unter Additional Options mit angeben.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>