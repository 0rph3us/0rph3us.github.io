<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Datenbank on Michael im Netz</title>
    <link>https://0rph3us.github.io/categories/datenbank/</link>
    <description>Recent content in Datenbank on Michael im Netz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>de-DE</language>
    <copyright>Diese Seite ist unter der &lt;a href=&#34;http://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt; lizenziert.</copyright>
    <lastBuildDate>Sun, 11 Dec 2011 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://0rph3us.github.io/categories/datenbank/rss/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>BigData mit Hypertable</title>
      <link>https://0rph3us.github.io/post/2011/12/bigdata-mit-hypertable/</link>
      <pubDate>Sun, 11 Dec 2011 00:00:00 +0000</pubDate>
      
      <guid>https://0rph3us.github.io/post/2011/12/bigdata-mit-hypertable/</guid>
      <description>&lt;p&gt;Ich beschäftige mich beruflich gerade mit &lt;a href=&#34;http://de.wikipedia.org/wiki/Big_Data&#34;&gt;Big Data&lt;/a&gt; und deren Verarbeitung. Ich habe nur ein Problem, dass ich keine &lt;em&gt;gute&lt;/em&gt; Hardware dafür habe, oder gar ein ganzes Rechenzentrum, wie Fratzenbuch oder google. Bei der Suche nach einem Lösungsansatz für mein Problem bin ich auf &lt;a href=&#34;http://hypertable.org/&#34;&gt;Hypertable&lt;/a&gt; gestoßen.&lt;/p&gt;
&lt;p&gt;
Wenn es um BigData geht, wird oft &lt;a href=&#34;http://hbase.apache.org/&#34;&gt;HBase&lt;/a&gt; genannt. In keinen kleinen Prototypen, war HBase in einer VM gefühlt viel langsamer als Hypertable. Deswegen habe ich mich weiter mit Hypertable und nicht mit HBase beschäftigt.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://hypertable.org/&#34;&gt;Hypertable&lt;/a&gt; ist eine verteilte Datenbank, welche vom Prinzip her &lt;a href=&#34;http://de.wikipedia.org/wiki/Spaltenorientierte_Datenbank&#34;&gt;spaltenorientiert&lt;/a&gt; ist. Dieses Prinzip kann mit Hilfe der &lt;a href=&#34;http://code.google.com/p/hypertable/wiki/ArchitecturalOverview&#34;&gt;Access Groups&lt;/a&gt; aufweichen. Man sollte auf keinen Fall versuchen aus Hypertable eine zeilenorientierte Datenbank zu machen.&lt;/p&gt;
&lt;p&gt;
Die aktuelle Zielarchitektur sieht wie folgt aus: Auf 12 Rechnern läuft &lt;a href=&#34;http://hadoop.apache.org/hdfs/&#34;&gt;HDFS&lt;/a&gt; von &lt;a href=&#34;http://hadoop.apache.org/&#34;&gt;Hadoop&lt;/a&gt;. Auf 11 von diesen Rechnern läuft eine RangeServer für Hypertable. Dieser ist auf 2 GB  RAM Verbrauch limitiert, weiterhin habe ich einen Hypertable Master. In meiner Testdatenbank habe ich 15,3 Millarden Datensätze. Auf dieser Datenmenge dauert ein random-Zugriff im Durchschnitt 200ms, wobei die worstcase Zeit einige Sekunden beträgt. Ich bin zumindest begeistert, dass ich derartig große Datenmengen auf schlechter Commodity Hardware handeln kann.  Ich bin mir sicher, dass ich mit der zur Verfügung stehenden Hardware noch mehr haus holen kann.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Letzte Rettung von MySQL</title>
      <link>https://0rph3us.github.io/post/2011/08/letzte-rettung-von-mysql/</link>
      <pubDate>Mon, 08 Aug 2011 00:00:00 +0000</pubDate>
      
      <guid>https://0rph3us.github.io/post/2011/08/letzte-rettung-von-mysql/</guid>
      <description>&lt;p&gt;
Ich hatte heute wieder Spaß mit &lt;a href=&#34;http://www.mysql.com/&#34;&gt;MySQL&lt;/a&gt;. Die &lt;a href=&#34;http://www.innodb.com/&#34;&gt;InnoDB&lt;/a&gt; Tabelle einer Datenbank hat sich erfolgreich selbst zerstört. Das hat sich dahingehend geäußert, dass sich &lt;a href=&#34;http://www.mysql.com/&#34;&gt;MySQL&lt;/a&gt; immer wieder neu gestartet hat. &lt;a href=&#34;http://www.mysql.com/&#34;&gt;MySQL&lt;/a&gt; war leider nicht in der Lage die betroffene Tabelle selbst wieder her zu stellen.&lt;/p&gt;
&lt;p&gt;
Mit Hilfe von &lt;a href=&#34;http://dev.mysql.com/doc/refman/5.0/en/forcing-innodb-recovery.html&#34;&gt;innodb_force_recovery&lt;/a&gt; kann man MySQL dazu bringen, dass es Tabellen wieder her stellt. Diese Option schreibt man einfach in die &lt;tt&gt;my.cnf&lt;/tt&gt;. Er kann die Werte von 1 bis 6 annehmen. Je höher der Wert ist, desto höher ist die Wahrscheinlichkeit, dass die Tabelle wieder hergestellt werden kann. Aber Achtung: Je größer der Wert ist, desto mehr Daten kann MySQL beim Wiederherstellen zerstören. Es ist deswegen ratsam den Wert inkrementell zu erhöhen, dieses Vorgehen dauert evtl. länger, aber man geht nicht in Gefahr unnötig Daten zu verlieren.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>