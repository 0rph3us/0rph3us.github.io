---
layout: post
title: Hadoop Cluster und das Netzwerk
categories:
- HPC
- Linux
tags:
- Architektur
- Cluster
- Hadoop
- Hardware
- Infiniband
- Linux
- Netzwerk
status: publish
type: post
published: true
meta:
  _edit_last: '2'
  _jd_tweet_this: 'yes'
  _wp_jd_wp: http://0rpheus.net/?p=6121
  _wp_jd_target: http://0rpheus.net/?p=6121
  _jd_wp_twitter: 'a:1:{i:0;s:68:"New post: Hadoop Cluster und das Netzwerk http://0rpheus.net/?p=6121";}'
author:
  login: rennecke
  email: michael.rennecke@gmail.com
  display_name: Michael Rennecke
  first_name: Michael
  last_name: Rennecke
---
<p>Ich habe mich heute wieder mit der Architektur von Hadoop-Clustern beschäftigt. Der Softwarestack ist relativ unspektakulär: Linux -&gt; Java -&gt; <a href="http://hadoop.apache.org/">Hadoop</a>. Beim Hardware-Stack scheiden sich etwas die Geister. Ich habe immer noch mit dem Gerücht zu kämpfen, dass man für Hadoop <em>Schrott-Rechner</em> verwenden kann. Hier wird der Begriff <em>Commodity Hardware</em> etwas falsch interpretiert. Commodity Hardware bezeichnet im Hadoop-Kontext keine spezielle Hardware verwendet wird. Große Datenbankensysteme verwenden in der Regel sehr spezielle Hardware.</p>
<p>Ich beobachte einen Trend, dass es immer mehr <a href="http://de.wikipedia.org/wiki/Appliance">Appliances</a> gibt, welche schon recht spezielle Netzwerktechnik verwenden, welche man ehr im klassischen HPC mit MPI vermuten würde. Wenn man sich die folgende Frage stellt, dann kommt man schnell selbst zu der Erkenntnis, dass man auch im Hadoop-Umfeld sehr spezielle Hardware benötigt.</p>
<p>Ich möchte das ganze einmal an einem Beispiel vorführen: Wenn man in einem Hadoop-Knoten 12 3TB große SAS Platten verbaut, dann ist es nicht unrealistisch, dass man 120 MB/s von jeder Platte lesen bzw. 100 MB/s schreiben kann und das über einen längeren Zeitraum. Daraus resultiert eine gesamte Bandbreite von 1440 MB/s bzw. 1200 MB/s. Wenn man sich diese Zahlen ansieht, dann ergibt es durchaus Sinn 2 10 GBit-Interfaces pro Node zu haben. Wenn man von komprimierten Daten im hdfs ausgeht, welche unkomprimiert versendet werden, dann können auch 2 QDR <a href="http://de.wikipedia.org/wiki/InfiniBand">Infiniband</a>-Interfaces (40 GBit/s) Sinn. Es gibt durchaus Anbieter, welche auf Infiniband setzten.</p>
<p>Durch die Administration und den Ausbau das Hadoop-Clusters meines Arbeitgebers kann ich bestätigen, dass die Daten nicht so lokal bleiben, wie man es sich das wünschen würde. Das ganze kann sich verschärfen, wenn man im Cluster noch eine Datenbank, wie <a href="http://hypertable.com/">Hypertable</a> betreibt.</p>
