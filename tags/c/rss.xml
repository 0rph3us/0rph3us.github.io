<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>C on Michael im Netz</title>
    <link>https://0rph3us.github.io/tags/c/</link>
    <description>Recent content in C on Michael im Netz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>de-DE</language>
    <copyright>Diese Seite ist unter der &lt;a href=&#34;http://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt; lizenziert.</copyright>
    <lastBuildDate>Wed, 18 Aug 2010 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://0rph3us.github.io/tags/c/rss/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Shared memory Allocator mit der STL</title>
      <link>https://0rph3us.github.io/post/2010/08/shared-memory-allocator-mit-der-stl/</link>
      <pubDate>Wed, 18 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>https://0rph3us.github.io/post/2010/08/shared-memory-allocator-mit-der-stl/</guid>
      <description>&lt;p&gt;
Ich habe mich die letzten Tage mit der &lt;a href=&#34;http://www.cplusplus.com/reference/stl/&#34;&gt;STL&lt;/a&gt; herungeärgert. Ich wollte einen Allocator schreiben, welcher mir die STL-Container in ein Shared Memory Segment legt. Ich habe es nicht wirklich hinbekommen. Inzwischen weiß ich, dass es die Leute von &lt;a href=&#34;http://www.boost.org/&#34;&gt;boost&lt;/a&gt; auch nicht hinbekommen haben. Aus diesem Grund werde ich nun &lt;a href=&#34;http://www.boost.org/&#34;&gt;boost&lt;/a&gt; benutzen und hoffen, dass die Performance nicht zu schlecht (unter &lt;a href=&#34;http://www.microsoft.com/germany/windows/&#34;&gt;Windows&lt;/a&gt;) ist. Das geheimnis ist, dass man die Container nach implementiert und die Implementierung kommt arbeitet korrekt in einem Shared Memory Segment.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mehrkern oder nicht Mehrkern, dass ist die Frage</title>
      <link>https://0rph3us.github.io/post/2010/06/mehrkern-oder-nicht-mehrkern-dass-ist-die-frage/</link>
      <pubDate>Mon, 21 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>https://0rph3us.github.io/post/2010/06/mehrkern-oder-nicht-mehrkern-dass-ist-die-frage/</guid>
      <description>&lt;p&gt;Ich habe inzwischen ein paar Experimente mit verschiedenen Mehrkernarchitekturen gemacht. Ich habe verschiende Algorithmen mit &lt;a href=&#34;http://en.wikipedia.org/wiki/Cilk&#34;&gt;Cilk++&lt;/a&gt; implementiert. Dabei kam es zu interessanten Ergebnissen. Ich hatte von superlinearen Speedup bis zu einem Speedup unter 1 alles. Aber woran liegt das, dass die Ergebnisse so weit auseinander gehen? Die schlechten Ergebnisse habe ich auf einem 2 Sockel &lt;a href=&#34;http://ark.intel.com/Product.aspx?id=33927&#34;&gt;Intel Xeon E5420&lt;/a&gt;-System mit 32 GB RAM gemacht. In der Mitte lag ein 2 Sockel System mit &lt;a href=&#34;http://ark.intel.com/Product.aspx?id=37111&#34;&gt;Intel Xeon X5570&lt;/a&gt; und 48 GB RAM Die besten Ergebnisse lieferte ein 4 Sockel Rechner mit 16 GB RAM und &lt;a href=&#34;http://www.cpu-world.com/CPUs/K8/AMD-Opteron%20852%20-%20OSP852FAA5BM.html&#34;&gt;AMD Opteron 852&lt;/a&gt; Prozessoren.&lt;/p&gt;
&lt;p&gt;
Eine Erklärung für das unterschiedliche abschneiden der Systeme ist die Anbindung an den RAM und die Caches. Bei dem AMD-System hat jeder (Einkern-) Prozessor privaten Cache und einen eignen Speicherkontroller. Hier gibt es keine Engpässe. Bei dem &lt;a href=&#34;http://ark.intel.com/Product.aspx?id=37111&#34;&gt;Intel Xeon X5570&lt;/a&gt; sind die Speicherkontroller in der CPU, aber der L2 Cache ist shared zwischen 2 Kernen. &lt;a href=&#34;http://www.intel.com/technology/platform-technology/hyper-threading/&#34;&gt;Hyperthreading&lt;/a&gt; hat keine Verbesserung der Laufzeit gebacht. Am schlechtesten schnitt das &lt;a href=&#34;http://ark.intel.com/Product.aspx?id=33927&#34;&gt;Intel Xeon E5420&lt;/a&gt;-System ab. Die beiden Prozessoren gehen über die Nordbrücke, um an den RAM zu gelangen. Ab einer bestimmten Problemgröße wurden die Algorithmen über die Speicherzugriffe sequenzialisiert.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dein Freund der Cachemiss</title>
      <link>https://0rph3us.github.io/post/2010/05/dein-freund-der-cachemiss/</link>
      <pubDate>Fri, 14 May 2010 00:00:00 +0000</pubDate>
      
      <guid>https://0rph3us.github.io/post/2010/05/dein-freund-der-cachemiss/</guid>
      <description>&lt;p&gt;
Ich habe in meinen &lt;a href=&#34;http://0rpheus.net/hpc/superlinearer-speedup&#34;&gt;letzten Eintrag &amp;uuml;ber Superlinearen Speedup&lt;/a&gt; geschrieben. Caching Effekte lassen sich auch in sequenziellen Programmen ausnutzen. So kann man l&amp;auml;sst sich die klassische Matrixmultiplikation um Gr&amp;ouml;&amp;szlig;enordnungen beschleunigen.&lt;/p&gt;
&lt;p&gt;
Dazu muss man nur die Matrix B transponiert abspeichern. Wenn man jetzt duch die Spalten der Matrix B geht hat man eine h&amp;ouml;here Lokalit&amp;auml;t und damit weniger Cachemisses.&lt;/p&gt;
&lt;pre lang=&#34;cpp&#34;&gt;
#include &lt;iostream&gt;
#include &lt;stdlib.h&gt;
#include &lt;time.h&gt;

using namespace std;

void mul(double *A, double *B, double *C, int dim)
{
    int i, j, k;
    double s;

    for (i = 0; i &lt; dim; i++){
        for (j = 0; j &lt; dim; j++) {
            s = 0.0;
            for (k = 0; k &lt; dim; ++k)
                s += A[dim*i +k] * B[dim*k+j];

            C[dim*i+j] = s;
        }
    }
}

void transpose(double *A, int dim){

        int i,j;
        double tmp;

    for (i = 0; i &lt; dim; i++){
        for (j = i; j &lt; dim; j++){
            tmp = A[dim*i+j];
            A[dim*i+j] =A[dim*j+i];
            A[dim*j+i] = tmp;
        }
    }

}

void mulfast(double *A, double *B, double *C, int dim)
{
    int i, j, k;
    double s;

    transpose(B, dim);

    for (i = 0; i &lt; dim; ++i){
        for (j = 0; j &lt; dim; ++j) {
            s = 0.0;
            for (k = 0; k &lt; dim; ++k)
                // B is transposed !!
                s += A[dim*i +k] * B[dim*j+k];

            C[dim*i+j] = s;
        }
    }

    transpose(B, dim);
}

int main(){

    int dim = 1024;
    clock_t start, end;

    double* A = (double*) calloc(dim* dim, sizeof(double));
    double* B = (double*) calloc(dim* dim, sizeof(double));
    double* C = (double*) calloc(dim* dim, sizeof(double));

    start = clock();
    mul(A,B,C, dim);
    end = clock();
    cout &lt;&lt; &#34;normal implementation: &#34; &lt;&lt; (end-start) / CLOCKS_PER_SEC &lt;&lt; &#34; seconds&#34; &lt;&lt; endl;

    start = clock();
    mulfast(A,B,C, dim);
    end = clock();
    cout &lt;&lt; &#34;fast implementation: &#34; &lt;&lt; (end-start) / CLOCKS_PER_SEC &lt;&lt; &#34; seconds&#34; &lt;&lt; endl;

    return 0;
}
&lt;/time.h&gt;&lt;/stdlib.h&gt;&lt;/iostream&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Superlinearer Speedup</title>
      <link>https://0rph3us.github.io/post/2010/05/superlinearer-speedup/</link>
      <pubDate>Fri, 14 May 2010 00:00:00 +0000</pubDate>
      
      <guid>https://0rph3us.github.io/post/2010/05/superlinearer-speedup/</guid>
      <description>&lt;p&gt;Ich habe für meine Diplomarbeit die &lt;a href=&#34;http://de.wikipedia.org/wiki/Strassen-Algorithmus&#34;&gt;Matrixmultiplikation nach Strassen&lt;/a&gt; implementiert. Das ganze habe ich mit
&lt;a href=&#34;http://en.wikipedia.org/wiki/Cilk&#34;&gt;Cilk++&lt;/a&gt; implementiert.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://0rph3us.github.io/strassen-results.png&#34; title=&#34;&#34; data-lightbox=&#34;set1&#34; data-title=&#34;Speedup von Matrixmultiplikation nach Strassen&#34;&gt;&lt;img src=&#34;https://0rph3us.github.io/strassen-results-thumbnail.png&#34; alt=&#34;superlinearer Speedup&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Ich war recht erstaunt, als ich diese Ergebnisse gesehen habe. Es ist erklärbar, weswegen ich einen superlinearen
&lt;a href=&#34;http://de.wikipedia.org/wiki/Speedup&#34;&gt;Speedup&lt;/a&gt; erreicht habe. Wenn ich auf 4 CPUs rechne habe ich mehr &lt;a href=&#34;http://de.wikipedia.org/wiki/Cache&#34;&gt;Cache&lt;/a&gt; zur Verfügung. Diesen hohen
Speedup kann man nur durch Caching Effekte erreichen.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>