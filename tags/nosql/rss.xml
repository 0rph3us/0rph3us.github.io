<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nosql on Michael im Netz</title>
    <link>http://localhost:1313/tags/nosql/</link>
    <description>Recent content in Nosql on Michael im Netz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>de-DE</language>
    <copyright>Diese Seite ist unter der &lt;a href=&#34;http://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt; lizenziert.</copyright>
    <lastBuildDate>Sun, 11 Dec 2011 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/nosql/rss/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>BigData mit Hypertable</title>
      <link>http://localhost:1313/post/2011/12/bigdata-mit-hypertable/</link>
      <pubDate>Sun, 11 Dec 2011 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2011/12/bigdata-mit-hypertable/</guid>
      <description>&lt;p&gt;Ich beschäftige mich beruflich gerade mit &lt;a href=&#34;http://de.wikipedia.org/wiki/Big_Data&#34;&gt;Big Data&lt;/a&gt; und deren Verarbeitung. Ich habe nur ein Problem, dass ich keine &lt;em&gt;gute&lt;/em&gt; Hardware dafür habe, oder gar ein ganzes Rechenzentrum, wie Fratzenbuch oder google. Bei der Suche nach einem Lösungsansatz für mein Problem bin ich auf &lt;a href=&#34;http://hypertable.org/&#34;&gt;Hypertable&lt;/a&gt; gestoßen.&lt;/p&gt;
&lt;p&gt;
Wenn es um BigData geht, wird oft &lt;a href=&#34;http://hbase.apache.org/&#34;&gt;HBase&lt;/a&gt; genannt. In keinen kleinen Prototypen, war HBase in einer VM gefühlt viel langsamer als Hypertable. Deswegen habe ich mich weiter mit Hypertable und nicht mit HBase beschäftigt.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://hypertable.org/&#34;&gt;Hypertable&lt;/a&gt; ist eine verteilte Datenbank, welche vom Prinzip her &lt;a href=&#34;http://de.wikipedia.org/wiki/Spaltenorientierte_Datenbank&#34;&gt;spaltenorientiert&lt;/a&gt; ist. Dieses Prinzip kann mit Hilfe der &lt;a href=&#34;http://code.google.com/p/hypertable/wiki/ArchitecturalOverview&#34;&gt;Access Groups&lt;/a&gt; aufweichen. Man sollte auf keinen Fall versuchen aus Hypertable eine zeilenorientierte Datenbank zu machen.&lt;/p&gt;
&lt;p&gt;
Die aktuelle Zielarchitektur sieht wie folgt aus: Auf 12 Rechnern läuft &lt;a href=&#34;http://hadoop.apache.org/hdfs/&#34;&gt;HDFS&lt;/a&gt; von &lt;a href=&#34;http://hadoop.apache.org/&#34;&gt;Hadoop&lt;/a&gt;. Auf 11 von diesen Rechnern läuft eine RangeServer für Hypertable. Dieser ist auf 2 GB  RAM Verbrauch limitiert, weiterhin habe ich einen Hypertable Master. In meiner Testdatenbank habe ich 15,3 Millarden Datensätze. Auf dieser Datenmenge dauert ein random-Zugriff im Durchschnitt 200ms, wobei die worstcase Zeit einige Sekunden beträgt. Ich bin zumindest begeistert, dass ich derartig große Datenmengen auf schlechter Commodity Hardware handeln kann.  Ich bin mir sicher, dass ich mit der zur Verfügung stehenden Hardware noch mehr haus holen kann.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>noSQL Datenbanken</title>
      <link>http://localhost:1313/post/2011/05/nosql-datenbanken/</link>
      <pubDate>Wed, 18 May 2011 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2011/05/nosql-datenbanken/</guid>
      <description>&lt;p&gt;
Ich arbeite inzwischen bei &lt;a href=&#34;http://www.unister.de/&#34;&gt;Unister&lt;/a&gt; als &lt;a href=&#34;http://0rpheus.net/privat/junior-system-architekt&#34;&gt;Junior Systemarchitekt&lt;/a&gt;. Zu meinen ersten Aufgaben hat gezählt eine Architektur für eine eine Datenbank zu schaffen, welche mit sehr hohen Schreibaufkommen zurecht kommt. Als Datenbank haben wir &lt;a href=&#34;http://www.mongodb.org/&#34;&gt;mongoDB&lt;/a&gt; benutzt. Dabei handelt es sich um eine &lt;a href=&#34;http://nosql-database.org/&#34;&gt;noSQL&lt;/a&gt;-Datenbank. Diese Dazenbanken haben kein festes Datenbankschema.&lt;/p&gt;
&lt;p&gt;
Die ersten Ergebnisse waren sehr erschütternd. Die Schreibperformence war einfach zu gering. Da man bei &lt;a href=&#34;http://www.mongodb.org/&#34;&gt;mongoDB&lt;/a&gt; nichts konfigurieren kann (Im Vergleich zu klassischen Datenbanken, wie MySQL oder PostgreSQL) war ich erst einmal ratlos. Das ganze konnte mit Clustern nicht verbessert werden. Eine genaue Untersuchung der Applikation hat ergeben, dass die Daten synchron und damit blockierend geschrieben wurden. Nachdem die Inserts nicht blockierend und in Batches umgesetzt wurden konnte schon ein Performancesprung festgestellt werden. Das konnte weiter verbessert werden, als wir die einzufügenden Daten in der Applikation nach dem Index vorsortiert eingefügt haben. Die Ursache liegt darin, das die Datenbank den Batch schneller abarbeiten kann und weniger Operationen auf dem Index nötig sind.&lt;/p&gt;
&lt;p&gt;
Zum Schluss möchte ich noch ein paar Worte zum Clustern von &lt;a href=&#34;http://www.mongodb.org/&#34;&gt;mongoDB&lt;/a&gt; verlieren. Es wird alles mitgebracht um schnell einen Cluster aufzusetzten. Ich habe es es leider geschafft, durch den Absturz von einem Knoten, den gesamten Cluster zu zerstören. Also sollte man bei Wichtigen Daten für Redundanz im Cluster sorgen. Es gibt auch viele Mittel in mongoDB um diese Redundanz zu erreichen.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>