<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hadoop on Michael im Netz</title>
    <link>http://localhost:1313/tags/hadoop/</link>
    <description>Recent content in Hadoop on Michael im Netz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>de-DE</language>
    <copyright>Diese Seite ist unter der &lt;a href=&#34;http://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt; lizenziert.</copyright>
    <lastBuildDate>Tue, 28 May 2013 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/hadoop/rss/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Hadoop Cluster und das Netzwerk</title>
      <link>http://localhost:1313/post/2013/05/hadoop-cluster-und-das-netzwerk/</link>
      <pubDate>Tue, 28 May 2013 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2013/05/hadoop-cluster-und-das-netzwerk/</guid>
      <description>&lt;p&gt;Ich habe mich heute wieder mit der Architektur von Hadoop-Clustern beschäftigt. Der Softwarestack ist relativ unspektakulär: Linux -&amp;gt; Java -&amp;gt; &lt;a href=&#34;http://hadoop.apache.org/&#34;&gt;Hadoop&lt;/a&gt;.
Beim Hardware-Stack scheiden sich etwas die Geister. Ich habe immer noch mit dem Gerücht zu kämpfen, dass man für Hadoop &lt;em&gt;Schrott-Rechner&lt;/em&gt;
verwenden kann. Hier wird der Begriff &lt;em&gt;Commodity Hardware&lt;/em&gt; etwas falsch interpretiert. Commodity Hardware bezeichnet im
Hadoop-Kontext keine spezielle Hardware verwendet wird. Große Datenbankensysteme verwenden in der Regel sehr spezielle Hardware.&lt;/p&gt;

&lt;p&gt;Ich beobachte einen Trend, dass es immer mehr &lt;a href=&#34;http://de.wikipedia.org/wiki/Appliance&#34;&gt;Appliances&lt;/a&gt; gibt, welche schon recht spezielle Netzwerktechnik verwenden,
welche man ehr im klassischen HPC mit MPI vermuten würde. Wenn man sich die folgende Frage stellt, dann kommt man schnell
selbst zu der Erkenntnis, dass man auch im Hadoop-Umfeld sehr spezielle Hardware benötigt.&lt;/p&gt;

&lt;p&gt;Ich möchte das ganze einmal an einem Beispiel vorführen: Wenn man in einem Hadoop-Knoten 12 3TB große SAS Platten verbaut,
dann ist es nicht unrealistisch, dass man 120 MB/s von jeder Platte lesen bzw. 100 MB/s schreiben kann und das über einen
längeren Zeitraum. Daraus resultiert eine gesamte Bandbreite von 1440 MB/s bzw. 1200 MB/s. Wenn man sich diese Zahlen ansieht,
dann ergibt es durchaus Sinn 2 10 GBit-Interfaces pro Node zu haben. Wenn man von komprimierten Daten im hdfs ausgeht,
welche unkomprimiert versendet werden, dann können auch 2 QDR &lt;a href=&#34;http://de.wikipedia.org/wiki/InfiniBand&#34;&gt;Infiniband&lt;/a&gt;-Interfaces (40 GBit/s) Sinn. Es gibt durchaus Anbieter,
welche auf Infiniband setzten.&lt;/p&gt;

&lt;p&gt;Durch die Administration und den Ausbau das Hadoop-Clusters meines Arbeitgebers kann ich bestätigen, dass die Daten nicht so lokal
bleiben, wie man es sich das wünschen würde. Das ganze kann sich verschärfen, wenn man im
Cluster noch eine Datenbank, wie &lt;a href=&#34;http://hypertable.com/&#34;&gt;Hypertable&lt;/a&gt; betreibt.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>